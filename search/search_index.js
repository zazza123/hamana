var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>     Illustrations by @gaiaparte </p> <p> </p> <p> Documentation: https://zazza123.github.io/hamana </p> <p>hamana (Hamster Analysis) is a Python library designed to simplify data analysis by combining the practicality of pandas and SQL in an open-source environment. This library was born from the experience of working in a large company where tools like <code>SAS</code> were often used as \"shortcuts\" to perform SQL queries across different data sources, without fully leveraging their potential. With the goal of providing a free and accessible alternative, <code>hamana</code> replicates these functionalities in an open-source context.</p>"},{"location":"index.html#why-choose-hamana","title":"Why Choose <code>hamana</code>?","text":"<ul> <li>Support for Multiple Data Sources: Connect to various data sources such as relational databases, CSV files, mainframes, and more.</li> <li>SQLite Integration: Save data locally in an SQLite database, either as a file or in memory.</li> <li>SQL + pandas: Combine the power of <code>SQL</code> with the flexibility of <code>pandas</code> for advanced analysis.</li> <li>Open Source: Available to everyone without licensing costs.</li> <li>Why \"Hamster\"?: Because hamsters are awesome!</li> </ul>"},{"location":"index.html#key-features","title":"Key Features","text":""},{"location":"index.html#1-data-extraction","title":"1. Data Extraction","text":"<p>Hamana allows you to extract data from a variety of sources:</p> <ul> <li>Relational databases (SQLite, Oracle, etc.)</li> <li>CSV, Excel, JSON, and other common file formats</li> <li>Legacy sources like mainframes</li> </ul> <p>Extractions are automatically saved as <code>pandas</code> DataFrames, making data manipulation simple and intuitive.</p>"},{"location":"index.html#2-sqlite-storage","title":"2. SQLite Storage","text":"<p>Each extraction can be saved in an SQLite database, enabling you to:</p> <ul> <li>Store data locally for future use</li> <li>Perform <code>SQL</code> queries to combine extractions from different sources</li> </ul>"},{"location":"index.html#3-data-analysis","title":"3. Data Analysis","text":"<p>With Hamana, you can:</p> <ul> <li>Use <code>pandas</code> to quickly and flexibly manipulate data</li> <li>Write <code>SQL</code> queries directly on datasets stored in SQLite</li> <li>Integrate <code>SQL</code> and <code>pandas</code> into a single workflow for advanced analysis</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<p>Hamana is available on PyPI, and you can install it easily with pip:</p> <pre><code>pip install hamana\n</code></pre>"},{"location":"index.html#usage-example","title":"Usage Example","text":"<p>Here is an example of how to use Hamana to connect to a data source, extract information, and combine it with another table:</p> <pre><code>import hamana as hm\n\n# connect hamana database\nhm.connect()\n\n# connect to Oracle database\noracle_db = hm.connector.db.Oracle.new(\n    host = \"localhost\",\n    port = 1521,\n    user = \"user\",\n    password = \"password\"\n)\n\n# define, execute and store a query\norders = hm.Query(\"SELECT * FROM orders\")\noracle_db.to_sqlite(orders, table_name = \"orders\")\n\n# load a CSV file and store it in SQLite\ncustomers = hm.connector.file.CSV(\"customers.csv\")\ncustomers.to_sqlite(table_name = \"customers\")\n\n# combine the two tables using SQL\ncustomers_orders = hm.execute(\"\"\"\n    SELECT\n          c.customer_name\n        , o.order_date\n        , o.total\n    FROM customers c\n    JOIN orders o ON\n        c.customer_id = o.customer_id\"\"\"\n)\n\n# use `pandas` for further analysis\nprint(customers_orders.result.head())\n\n# close connection\nhm.disconnect()\n</code></pre>"},{"location":"index.html#how-to-contribute","title":"How to Contribute","text":"<p>If you want to contribute to Hamana:</p> <ol> <li>Fork the repository.</li> <li> <p>Create a branch for your changes:</p> <pre><code>git checkout -b feature/your-feature-name\n</code></pre> </li> <li> <p>Submit a pull request describing the changes.</p> </li> </ol> <p>All contributions are welcome!</p>"},{"location":"index.html#license","title":"License","text":"<p>This project is distributed under the BSD 3-Clause \"New\" or \"Revised\" license.</p>"},{"location":"index.html#contact","title":"Contact","text":"<p>For questions or suggestions, you can open an Issue on GitHub or contact me directly.</p> <p>Thank you for choosing Hamana!</p>"},{"location":"usage.html","title":"Usage","text":"<p>This page provides a detailed explanation of <code>hamana</code>'s core functionalities and an overview of its available connectors. By the end, you'll have a clear understanding of how to utilize <code>hamana</code> effectively in your data analysis workflows.</p>"},{"location":"usage.html#sqlite-database-management","title":"SQLite Database Management","text":"<p><code>hamana</code> is designed to facilitate data analysis using an internal SQLite database. Here's how it works:</p>"},{"location":"usage.html#connecting-to-the-database","title":"Connecting to the Database","text":"<p>Use the <code>connect</code> function to create or connect to an SQLite database. By default, the database is loaded in memory, making it ideal for quick analysis and small datasets. For more complex analyses or larger datasets, you can specify a <code>.db</code> file path, which will either be created or loaded automatically.</p> <ul> <li>In-memory example:</li> </ul> <pre><code>import hamana as hm\n\n# connect to an in-memory SQLite database\nhm.connect()\n</code></pre> <ul> <li>File-based example:</li> </ul> <pre><code># connect to an SQLite database stored in a file\nhm.connect(\"data_analysis.db\")\n</code></pre>"},{"location":"usage.html#disconnecting-from-the-database","title":"Disconnecting from the Database","text":"<p>Once you're done with your analysis, you can disconnect from the database using the <code>disconnect</code> function:</p> <pre><code># disconnect from the database\nhm.disconnect()\n</code></pre> <p>Note: <code>hamana</code> ensures consistency by allowing only one active database instance at a time. This design is particularly suited for workflows in Jupyter Notebooks.</p>"},{"location":"usage.html#data-connectors","title":"Data Connectors","text":"<p>The power of <code>hamana</code> lies in its ability to load data into the SQLite database from various sources using connectors. These connectors are categorized based on the type of data source:</p>"},{"location":"usage.html#available-connectors","title":"Available Connectors","text":""},{"location":"usage.html#1-relational-database-connectors","title":"1. Relational Database Connectors","text":"<p><code>hamana</code> supports several relational databases, including Oracle, Teradata, SQLite (external databases) and many others planned for future releases.</p> <p>Example:</p> <pre><code>from hamana.connector.db import Oracle\n\n# extract data from an Oracle database\noracle_db = Oracle.new(\n    host = \"localhost\",\n    port = 1521,\n    user = \"user\",\n    password = \"password\"\n)\nemployees = oracle_db.execute(\"SELECT * FROM employees\")\n</code></pre>"},{"location":"usage.html#2-file-connectors","title":"2. File Connectors","text":"<p><code>hamana</code> can load data from various file types, such as CSV, JSON, Fixed-width positional files.</p> <p>Example:</p> <pre><code>from hamana.connector.file import CSV\n\n# load data from a CSV file\ncsv_file = CSV(\"data/orders.csv\")\norders = csv_file.execute()\n</code></pre>"},{"location":"usage.html#modular-design","title":"Modular Design","text":"<p>Connectors are modularly organized under <code>hamana.connector</code> with extensions for specific types of sources:</p> <ul> <li><code>.db</code>: For database connectors.</li> <li><code>.file</code>: For file connectors.</li> </ul> <p>This structure ensures scalability, allowing more connectors to be added over time.</p>"},{"location":"usage.html#connectors-overview","title":"Connectors Overview","text":"<p>The following table provides a detailed summary of the available connectors:</p> Type Sources Path Connector Relational Database Oracle <code>hamana.connector.db</code> Oracle Relational Database Teradata <code>hamana.connector.db</code> Teradata Relational Database SQLite <code>hamana.connector.db</code> SQLite File Connector CSV <code>hamana.connector.file</code> CSV File Connector JSON <code>hamana.connector.file</code> JSON File Connector Positional Files <code>hamana.connector.file</code> PositionalFile <p>Each connector's page provides detailed usage instructions and examples.</p>"},{"location":"connector/db/index.html","title":"Database Connectors","text":"<p>The <code>hamana.connector.db</code> package provides a set of connectors to interact with databases. The package is designed to be extensible and easy to use.</p> <p>Each connector must inherit from the <code>DatabaseConnectorABC</code> abstract class that provides a guideline for the implementation of the connector, see the Interface section for more details. From a high-level perspective, a connector must implement the following methods:</p> <ul> <li><code>_connect</code>: return the <code>Connection</code> object used to interact with the database.</li> <li><code>__enter__</code>: establish a connection to the database.</li> <li><code>__exit__</code>: close the connection to the database.</li> <li><code>ping</code>: check if the connection to the database is still valid.</li> <li><code>execute</code>: execute a query on the database. This approach could be useful for queries that rerturn a limited number of rows because the results are stored in memory.</li> <li><code>batch_execute</code>: similar to <code>execute</code>, but it is designed to handle queries that return a large number of rows. The function returns a generator that yields the results by a batch of rows.</li> <li><code>to_sqlite</code>: this method execute the query and store the results in a dedicated table in the internal <code>hamana</code> SQLite database. This approach is useful to store the results of a query and use them later in the analysis.</li> </ul> <p>See more details in the method's description in the Interface section.</p> <p>For all the databases admitting python library that follow PEP 249 \"Python Database API Specification v2.0\", <code>hamana.connector.db</code> package provides the <code>BaseConnector</code> class with a base implementation of the <code>DatabaseConnectorABC</code> interface. It is recommended to inherit from this class to implement a new connector, see the Base Connector section for more details.</p> <p>The following example shows how to connect to an Oracle database, execute a query, and store the results in the internal <code>hamana</code> SQLite database.</p> <pre><code>import hamana as hm\n\n# connect hamana database\nhm.connect()\n\n# connect Oracle database\noracle_db = hm.connector.db.Oracle.new(\n    host = \"localhost\",\n    port = 1521,\n    user = \"user\",\n    password = \"password\"\n)\n\n# execute and store a query\noracle_db.to_sqlite(\n    query = hm.Query(\"SELECT * FROM orders\"),\n    table_name = \"orders\"\n)\n\n# disconnect\nhm.disconnect()\n</code></pre> <p>The current available connectors are:</p> Sources Path Connector Oracle <code>hamana.connector.db</code> Oracle SQLite <code>hamana.connector.db</code> SQLite Teradata <code>hamana.connector.db</code> Teradata"},{"location":"connector/db/index.html#interface","title":"Interface","text":""},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC","title":"hamana.connector.db.interface.DatabaseConnectorABC","text":"<p>The following abstract class defines a general database connector. A connector is used in order to connect to a database and perform operations on it.</p> <p>All <code>hamana</code> connectors must inherit from this class.</p>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.connection","title":"connection  <code>instance-attribute</code>","text":"<pre><code>connection: ConnectionProtocol\n</code></pre> <p>Database connection.</p> <p>This attribute is used to store the connection to the database  and must satisfy the PEP 249 Standard Database API Specification v2.0.</p>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.__enter__","title":"__enter__  <code>abstractmethod</code>","text":"<pre><code>__enter__() -&gt; 'DatabaseConnectorABC'\n</code></pre> <p>Open a connection.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef __enter__(self) -&gt; \"DatabaseConnectorABC\":\n    \"\"\"Open a connection.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.__exit__","title":"__exit__  <code>abstractmethod</code>","text":"<pre><code>__exit__(\n    exc_type: Any, exc_value: Any, traceback: Any\n) -&gt; None\n</code></pre> <p>Close a connection.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -&gt; None:\n    \"\"\"Close a connection.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.ping","title":"ping  <code>abstractmethod</code>","text":"<pre><code>ping() -&gt; None\n</code></pre> <p>Function used to check the database connection.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef ping(self) -&gt; None:\n    \"\"\"Function used to check the database connection.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.parse_cursor_description","title":"parse_cursor_description  <code>abstractmethod</code>","text":"<pre><code>parse_cursor_description(\n    cursor: Cursor,\n) -&gt; dict[str, Column | None]\n</code></pre> <p>The function is used to take a cursor object,  parse its description, and extract a corresponding list  of <code>Column</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>cursor</code> <code>Cursor</code> <p>cursor to parse.</p> required <p>Returns:</p> Type Description <code>dict[str, Column | None]</code> <p>dictionary containing the columns extracted from the cursor.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef parse_cursor_description(self, cursor: Cursor) -&gt; dict[str, Column | None]:\n    \"\"\"\n        The function is used to take a cursor object, \n        parse its description, and extract a corresponding list \n        of `Column` objects.\n\n        Parameters:\n            cursor: cursor to parse.\n\n        Returns:\n            dictionary containing the columns extracted from the cursor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.get_column_from_dtype","title":"get_column_from_dtype  <code>abstractmethod</code>","text":"<pre><code>get_column_from_dtype(\n    dtype: Any, column_name: str, order: int\n) -&gt; Column\n</code></pre> <p>This function is designed to create a mapping between the  datatypes provided by the different database connectors and  standard <code>hamana</code> datatypes.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>Any</code> <p>data type of the column.</p> required <code>column_name</code> <code>str</code> <p>name of the column.</p> required <code>order</code> <code>int</code> <p>order of the column.</p> required <p>Returns:</p> Type Description <code>Column</code> <p><code>Column</code> object representing the column.</p> <p>Raises:</p> Type Description <code>ColumnDataTypeConversionError</code> <p>if the datatype  does not have a corresponding mapping.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef get_column_from_dtype(self, dtype: Any, column_name: str, order: int) -&gt; Column:\n    \"\"\"\n        This function is designed to create a mapping between the \n        datatypes provided by the different database connectors and \n        standard `hamana` datatypes.\n\n        Parameters:\n            dtype: data type of the column.\n            column_name: name of the column.\n            order: order of the column.\n\n        Returns:\n            `Column` object representing the column.\n\n        Raises:\n            ColumnDataTypeConversionError: if the datatype \n                does not have a corresponding mapping.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.execute","title":"execute  <code>abstractmethod</code>","text":"<pre><code>execute(query: Query | str) -&gt; None | Query\n</code></pre> <p>Function used to extract data from the database by  executin a SELECT query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Query | str</code> <p>query to execute on database. The query could be  a string or a <code>Query</code> object. If the query is a string,  then the function automatically creates a <code>Query</code> object.</p> required <p>Returns:</p> Type Description <code>None | Query</code> <p>The result depends on the input provided.  If query is a string, then  the function automatically  creates a <code>Query</code> object, executes the extraction and  returns the <code>Query</code> object with the result.  If query is a <code>Query</code> object, then the function performs  the extraction and return None because the result is stored  in the object itself.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef execute(self, query: Query | str) -&gt; None | Query:\n    \"\"\"\n        Function used to extract data from the database by \n        executin a SELECT query.\n\n        Parameters:\n            query: query to execute on database. The query could be \n                a string or a `Query` object. If the query is a string, \n                then the function automatically creates a `Query` object.\n\n        Returns:\n            The result depends on the input provided. \n                If query is a string, then  the function automatically \n                creates a `Query` object, executes the extraction and \n                returns the `Query` object with the result. \n                If query is a `Query` object, then the function performs \n                the extraction and return None because the result is stored \n                in the object itself.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.batch_execute","title":"batch_execute  <code>abstractmethod</code>","text":"<pre><code>batch_execute(\n    query: Query, batch_size: int\n) -&gt; Generator[Any, None, None]\n</code></pre> <p>Function used to execute a query on the database and return the results in batches.  This approach is used to avoid memory issues when dealing with large datasets.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Query</code> <p>query to execute on database.</p> required <code>batch_size</code> <code>int</code> <p>size of the batch to return.</p> required <p>Returns:</p> Type Description <code>None</code> <p>Generator used to return the results in batches.</p> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef batch_execute(self, query: Query, batch_size: int) -&gt; Generator[Any, None, None]:\n    \"\"\"\n        Function used to execute a query on the database and return the results in batches. \n        This approach is used to avoid memory issues when dealing with large datasets.\n\n        Parameters:\n            query: query to execute on database.\n            batch_size: size of the batch to return.\n\n        Returns:\n            Generator used to return the results in batches.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#hamana.connector.db.interface.DatabaseConnectorABC.to_sqlite","title":"to_sqlite  <code>abstractmethod</code>","text":"<pre><code>to_sqlite(\n    query: Query,\n    table_name: str,\n    raw_insert: bool = False,\n    batch_size: int = 10000,\n    mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE,\n) -&gt; None\n</code></pre> <p>This function is used to extract data from the database and insert it  into the <code>hamana</code> internal database (<code>HamanaConnector</code>).</p> <p>The <code>hamana</code> db is a SQLite database, for this reason  <code>bool</code>, <code>datetime</code> and <code>timestamp</code> data types are not supported. If some of the columns are defined with these data types,  then the method could perform an automatic conversion to  a SQLite data type.</p> <p>The conversions are:</p> <ul> <li><code>bool</code> columns are mapped to <code>INTEGER</code> data type, with the values      <code>True</code> and <code>False</code> converted to <code>1</code> and <code>0</code>.</li> <li><code>datetime</code> columns are mapped to <code>REAL</code> data type, with the values      converted to a float number using the following format: <code>YYYYMMDD.HHmmss</code>.     Observe that the integer part represents the date in the format <code>YYYYMMDD</code>,     while the decimal part represents the time component in the format <code>HHmmss</code>.</li> </ul> <p>By default, the method performs the automatic datatype  conversion. However, use the parameter <code>raw_insert</code> to  avoid this conversion and improve the INSERT efficiency. </p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Query</code> <p>query to execute on database.</p> required <code>table_name</code> <code>str</code> <p>name of the table to insert the data. By assumption, the table's name is converted to uppercase.</p> required <code>raw_insert</code> <code>bool</code> <p>bool value to disable/activate the datatype  conversion during the INSERT process. By default, it is  set to <code>False</code>.</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>size of the batch used during the inserting process.</p> <code>10000</code> <code>mode</code> <code>SQLiteDataImportMode</code> <p>mode of importing the data into the database.</p> <code>SQLiteDataImportMode.REPLACE</code> Source code in <code>src/hamana/connector/db/interface.py</code> <pre><code>@abstractmethod\ndef to_sqlite(self, query: Query, table_name: str, raw_insert: bool = False, batch_size: int = 10_000, mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE) -&gt; None:\n    \"\"\"\n        This function is used to extract data from the database and insert it \n        into the `hamana` internal database (`HamanaConnector`).\n\n        The `hamana` db is a SQLite database, for this reason \n        `bool`, `datetime` and `timestamp` data types are not supported.\n        If some of the columns are defined with these data types, \n        then the method could perform an automatic conversion to \n        a SQLite data type.\n\n        The conversions are:\n\n        - `bool` columns are mapped to `INTEGER` data type, with the values \n            `True` and `False` converted to `1` and `0`.\n        - `datetime` columns are mapped to `REAL` data type, with the values \n            converted to a float number using the following format: `YYYYMMDD.HHmmss`.\n            Observe that the integer part represents the date in the format `YYYYMMDD`,\n            while the decimal part represents the time component in the format `HHmmss`.\n\n        By default, the method performs the automatic datatype \n        conversion. However, use the parameter `raw_insert` to \n        **avoid** this conversion and improve the INSERT efficiency. \n\n        Parameters:\n            query: query to execute on database.\n            table_name: name of the table to insert the data.\n                By assumption, the table's name is converted to uppercase.\n            raw_insert: bool value to disable/activate the datatype \n                conversion during the INSERT process. By default, it is \n                set to `False`.\n            batch_size: size of the batch used during the inserting process.\n            mode: mode of importing the data into the database.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"connector/db/index.html#base-connector","title":"Base Connector","text":"<p>The <code>BaseConnector</code> class provides a base implementation of the <code>DatabaseConnectorABC</code> interface. It is recommended to inherit from this class to implement a new connectors that follow the PEP 249 \"Python Database API Specification v2.0\".</p> <p>The only methods that must be implemented are:</p> <ul> <li><code>__init__</code>: method that should initialize the connection to the database.</li> <li><code>_connect</code>: method returning the <code>Connection</code> object used to interact with the database.</li> </ul>"},{"location":"connector/db/index.html#hamana.connector.db.base.BaseConnector","title":"hamana.connector.db.base.BaseConnector","text":"<p>               Bases: <code>DatabaseConnectorABC</code></p> <p>Class representing a generic database connector that can be  used to define new database connectors satisfying the  Python Database API Specification v2.0.</p> <p>New connectors that inherit from this class must implement  the <code>_connect</code> method returning the connection proper connection  object satisfying PEP 249.</p>"},{"location":"connector/db/exceptions.html","title":"Exceptions and Warnings","text":"<p>This section is dedicated present the exceptions and warnings related to database connectors.</p>"},{"location":"connector/db/exceptions.html#hamana.connector.db.exceptions","title":"hamana.connector.db.exceptions","text":""},{"location":"connector/db/exceptions.html#hamana.connector.db.exceptions.HamanaConnectorAlreadyInitialised","title":"HamanaConnectorAlreadyInitialised","text":"<pre><code>HamanaConnectorAlreadyInitialised()\n</code></pre> <p>               Bases: <code>HamanaException</code></p> <p>Exception to raise when HamanaConnector is already initialised</p> Source code in <code>src/hamana/connector/db/exceptions.py</code> <pre><code>def __init__(self):\n    super().__init__(\"HamanaConnector is already initialised.\")\n</code></pre>"},{"location":"connector/db/exceptions.html#hamana.connector.db.exceptions.HamanaConnectorNotInitialised","title":"HamanaConnectorNotInitialised","text":"<pre><code>HamanaConnectorNotInitialised()\n</code></pre> <p>               Bases: <code>HamanaException</code></p> <p>Exception to raise when HamanaConnector is not initialised.</p> Source code in <code>src/hamana/connector/db/exceptions.py</code> <pre><code>def __init__(self):\n    super().__init__(\"No instance of HamanaConnector is initialised.\")\n</code></pre>"},{"location":"connector/db/hamana.html","title":"Hamana","text":"<p>One of the features of <code>hamana</code> library is the possibility to initiate a connection to a locally (or in memory) SQLite database that can be used to cetralize the data storage from various sources (by using the different connectors available in the library), and perform the analysis using the <code>SQL</code> language or <code>pandas</code> library. </p> <p>To ensure consistency, it is possible to have only one single instance of the database that can be shared among different connectors. The database is created in memory by default, but it is possible to store it in a file by providing the <code>path</code> parameter when it is initiated.</p> <p>Even if the internal database is of SQLite type, it was implemented a dedicated connector <code>HamanaConnector</code> to handle the single instance behavior, that inherits from the <code>SQLiteConnector</code> class. To work with the database, it is necessary first to create an instance of the <code>HamanaConnector</code> class or use the <code>hamana.connect()</code> method as a shortcut. Once the database is not needed anymore, it is possible to close the connection by calling the <code>HamanaConnector.close()</code> method or using the <code>hamana.disconnect()</code> shortcut.</p> <pre><code>import hamana as hm\n\n# connect to internal database\nhm.connect()\n\n# perform operations with the database\n# ...\n\n# disconnect from the database\nhm.disconnect()\n</code></pre> <p>The above example shows how to work with the internal database by using the corresponding shortcuts. The <code>hamana.connect()</code> method creates a new instance of the <code>HamanaConnector</code> class and stores it in the <code>hamana</code> module, while the <code>hamana.disconnect()</code> method closes the connection and removes the instance from the <code>hamana</code> module. The next example, is equivalent to the previous one, but it shows how to work with the <code>HamanaConnector</code> class directly.</p> <pre><code>from hamana.connector.db.hamana import HamanaConnector\n\n# create a new instance of the HamanaConnector class\nhamana_db = HamanaConnector()\n\n# perform operations with the database\n# ...\n\n# disconnect from the database\nhamana_db.close()\n</code></pre>"},{"location":"connector/db/hamana.html#hamanaconnector","title":"HamanaConnector","text":""},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.HamanaConnector","title":"hamana.connector.db.hamana.HamanaConnector","text":"<pre><code>HamanaConnector(path: str | Path = ':memory:')\n</code></pre> <p>               Bases: <code>SQLiteConnector</code></p> <p>This class is responsible for handling the database connection of the library. For each execution, only one instance of this class is allowed to manage a single  database connection.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>path like string that define the SQLite database to load/create. By default the database is created in memory.</p> <code>':memory:'</code> <p>Example <pre><code>from hamana.connector.db.hamana import HamanaConnector\n\n# init internal database\nhamana_db = HamanaConnector()\n\n# doing operations..\nquery.to_sqlite(table_name = \"t_oracle_output\")\n\n# close connection\nhamana_db.close()\n</code></pre></p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def __init__(self, path: str | Path = \":memory:\") -&gt; None:\n    path_str = str(path)\n    super().__init__(path_str)\n    self._connection = sqlite_connect(database = path_str)\n</code></pre>"},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.HamanaConnector.get_instance","title":"get_instance  <code>classmethod</code>","text":"<pre><code>get_instance() -&gt; HamanaConnector\n</code></pre> <p>Get the instance of the internal database connector.</p> <p>Raises:</p> Type Description <code>HamanaConnectorNotInitialised</code> <p>If the database is not initialized.</p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>@classmethod\ndef get_instance(cls) -&gt; \"HamanaConnector\":\n    \"\"\"\n        Get the instance of the internal database connector.\n\n        Raises:\n            HamanaConnectorNotInitialised: If the database is not initialized.\n    \"\"\"\n    logger.debug(\"start\")\n    _instance = cls._instances.get(cls)\n\n    if _instance is None:\n        logger.error(\"HamanaConnector is not initialized.\")\n        raise HamanaConnectorNotInitialised()\n\n    logger.debug(\"end\")\n    return _instance\n</code></pre>"},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.HamanaConnector.get_connection","title":"get_connection","text":"<pre><code>get_connection() -&gt; Connection\n</code></pre> <p>Get the database connection.</p> <p>Raises:</p> Type Description <code>HamanaConnectorNotInitialised</code> <p>If the database is not initialized.</p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def get_connection(self) -&gt; Connection:\n    \"\"\"\n        Get the database connection.\n\n        Raises:\n            HamanaConnectorNotInitialised: If the database is not initialized.\n    \"\"\"\n    logger.debug(\"start\")\n    if self._connection is None:\n        logger.error(\"Database connection is not initialized.\")\n        raise HamanaConnectorNotInitialised()\n    logger.debug(\"end\")\n    return self._connection\n</code></pre>"},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.HamanaConnector.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the database connection. Use this method at the end of the process to ensure that the database  connection is properly closed. If the connection is already closed,  this method will log a warning message.</p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n        Close the database connection.  \n        Use this method at the end of the process to ensure that the database \n        connection is properly closed. If the connection is already closed, \n        this method will log a warning message.\n    \"\"\"\n    logger.debug(\"start\")\n    if self._connection is None:\n        logger.warning(\"Database connection is already closed.\")\n    else:\n        self._connection.close()\n        self._connection = None\n\n        # remove instance from singleton\n        HamanaConnector._instances.pop(HamanaConnector)\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/db/hamana.html#shortcut-methods","title":"Shortcut Methods","text":""},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.connect","title":"hamana.connector.db.hamana.connect","text":"<pre><code>connect(path: str | Path = ':memory:') -&gt; None\n</code></pre> <p>Connect to the database using the path provided. This function is a helper function to connect to the database  without creating an instance of the <code>HamanaConnector</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>path like string that define the SQLite database to load/create. By default the database is created in memory.</p> <code>':memory:'</code> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def connect(path: str | Path = \":memory:\") -&gt; None:\n    \"\"\"\n        Connect to the database using the path provided.  \n        This function is a helper function to connect to the database \n        without creating an instance of the `HamanaConnector` class.\n\n        Parameters:\n            path: path like string that define the SQLite database to load/create.  \n                By default the database is created in memory.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # create connection\n    HamanaConnector(path)\n    logger.info(f\"Connected to the database ({path}).\")\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.execute","title":"hamana.connector.db.hamana.execute","text":"<pre><code>execute(query: str) -&gt; Query\n</code></pre><pre><code>execute(query: Query) -&gt; None\n</code></pre> <pre><code>execute(query: Query | str) -&gt; None | Query\n</code></pre> <p>Execute the query on the internal database. This function is a helper function to execute a query on the <code>hamana</code> SQLite database.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Query | str</code> <p>query to execute on database. The query could be  a string or a <code>Query</code> object. If the query is a string,  then the function automatically creates a <code>Query</code> object.</p> required <p>Returns:</p> Type Description <code>None | Query</code> <p>The result depends on the input provided.  If query is a string, then  the function automatically  creates a <code>Query</code> object, executes the extraction and  returns the <code>Query</code> object with the result.  If query is a <code>Query</code> object, then the function performs  the extraction and return None because the result is stored  in the object itself.</p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def execute(query: Query | str) -&gt; None | Query:\n    \"\"\"\n        Execute the query on the internal database.  \n        This function is a helper function to execute a query on the `hamana` SQLite database.\n\n        Parameters:\n            query: query to execute on database. The query could be \n                a string or a `Query` object. If the query is a string, \n                then the function automatically creates a `Query` object.\n\n        Returns:\n            The result depends on the input provided. \n                If query is a string, then  the function automatically \n                creates a `Query` object, executes the extraction and \n                returns the `Query` object with the result. \n                If query is a `Query` object, then the function performs \n                the extraction and return None because the result is stored \n                in the object itself.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # execute query\n    result = HamanaConnector.get_instance().execute(query)\n    logger.info(f\"Query executed successfully: {query}\")\n\n    logger.debug(\"end\")\n    return result\n</code></pre>"},{"location":"connector/db/hamana.html#hamana.connector.db.hamana.disconnect","title":"hamana.connector.db.hamana.disconnect","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from the database. This function is a helper function to disconnect from the database  without using an instance of the <code>HamanaConnector</code> class.</p> Source code in <code>src/hamana/connector/db/hamana.py</code> <pre><code>def disconnect() -&gt; None:\n    \"\"\"\n        Disconnect from the database.  \n        This function is a helper function to disconnect from the database \n        without using an instance of the `HamanaConnector` class.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # close connection\n    HamanaConnector.get_instance().close()\n    logger.info(\"Disconnected from the database.\")\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/db/oracle.html","title":"Oracle","text":"<p>To connect to an Oracle database, is possible to import the <code>OracleConnector</code> class from the <code>hamana.connector.db.oracle</code> module. As a shortcut, the <code>OracleConnector</code> class is also available in the <code>hamana.connector.db</code> module as <code>Oracle</code>.</p> <pre><code>import hamana as hm\n\n# connect database\noracle_db = hm.connector.db.Oracle.new(\n    host = \"localhost\",\n    port = 1521,\n    user = \"user\",\n    password = \"password\"\n)\n\n# perform operations\n# ...\n</code></pre>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle","title":"hamana.connector.db.oracle","text":""},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig","title":"OracleConnectorConfig  <code>dataclass</code>","text":"<pre><code>OracleConnectorConfig(\n    host: str | None = None,\n    port: int = 1521,\n    user: str | None = None,\n    password: str | None = None,\n    service: str | None = None,\n    data_source_name: str | None = None,\n)\n</code></pre> <p>               Bases: <code>DatabaseConnectorConfig</code></p> <p>Class to represent the configuration of an Oracle database.</p>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig.port","title":"port  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>port: int = 1521\n</code></pre> <p>Port of the database. Default is 1521.</p>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig.service","title":"service  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>service: str | None = None\n</code></pre> <p>Service name of the database.</p>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig.data_source_name","title":"data_source_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data_source_name: str | None = None\n</code></pre> <p>DSN connection string to connect on the database.</p>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig.connect_params","title":"connect_params  <code>property</code>","text":"<pre><code>connect_params: ConnectParams\n</code></pre> <p>Get the connection parameters to connect on the database.</p>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnectorConfig.get_data_source_name","title":"get_data_source_name","text":"<pre><code>get_data_source_name() -&gt; str\n</code></pre> <p>Get the DSN connection string to connect on the database.</p> Source code in <code>src/hamana/connector/db/oracle.py</code> <pre><code>def get_data_source_name(self) -&gt; str:\n    \"\"\"Get the DSN connection string to connect on the database.\"\"\"\n    return self.data_source_name if self.data_source_name else self.connect_params.get_connect_string()\n</code></pre>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnector","title":"OracleConnector","text":"<pre><code>OracleConnector(\n    config: OracleConnectorConfig, **kwargs: dict[str, Any]\n)\n</code></pre> <p>               Bases: <code>BaseConnector</code></p> <p>Class representing a connector to an Oracle database.</p> Source code in <code>src/hamana/connector/db/oracle.py</code> <pre><code>def __init__(self, config: OracleConnectorConfig, **kwargs: dict[str, Any]) -&gt; None:\n    self.config = config\n    self.kwargs = kwargs\n    self.connection: Connection\n</code></pre>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnector.create_config","title":"create_config  <code>classmethod</code>","text":"<pre><code>create_config(\n    user: str,\n    password: str,\n    host: str | None = None,\n    service: str | None = None,\n    port: int = 1521,\n    data_source_name: str | None = None,\n) -&gt; OracleConnectorConfig\n</code></pre> <p>Use this function to create a new Oracle connector configuration.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>User to connect to the database.</p> required <code>password</code> <code>str</code> <p>Password to uso to connect to the database.</p> required <code>host</code> <code>str | None</code> <p>Host of the database.</p> <code>None</code> <code>service</code> <code>str | None</code> <p>Service name of the database.</p> <code>None</code> <code>port</code> <code>int</code> <p>Port of the database.</p> <code>1521</code> <code>data_source_name</code> <code>str | None</code> <p>DSN connection string to connect on the database.  Observe that if DSN is provided, then host, service and port are ignored.</p> <code>None</code> <p>Returns:</p> Type Description <code>OracleConnectorConfig</code> <p>Oracle connector configuration.</p> Source code in <code>src/hamana/connector/db/oracle.py</code> <pre><code>@classmethod\ndef create_config(\n    cls,\n    user: str,\n    password: str,\n    host: str | None = None,\n    service: str | None = None,\n    port: int = 1521,\n    data_source_name: str | None = None\n) -&gt; OracleConnectorConfig:\n    \"\"\"\n        Use this function to create a new Oracle connector configuration.\n\n        Parameters:\n            user: User to connect to the database.\n            password: Password to uso to connect to the database.\n            host: Host of the database.\n            service: Service name of the database.\n            port: Port of the database.\n            data_source_name: DSN connection string to connect on the database. \n                Observe that if DSN is provided, then host, service and port are ignored.\n\n        Returns:\n            Oracle connector configuration.\n    \"\"\"\n    logger.debug(\"start\")\n\n    if data_source_name:\n        logger.debug(\"data source name provided\")\n        config = OracleConnectorConfig(user = user, password = password, data_source_name = data_source_name)\n    else:\n        logger.debug(f\"host: {host}, service: {service}, port: {port}\")\n        config = OracleConnectorConfig(user = user, password = password, host = host, service = service, port = port)\n\n    logger.debug(\"end\")\n    return config\n</code></pre>"},{"location":"connector/db/oracle.html#hamana.connector.db.oracle.OracleConnector.new","title":"new  <code>classmethod</code>","text":"<pre><code>new(\n    user: str,\n    password: str,\n    host: str | None = None,\n    service: str | None = None,\n    port: int = 1521,\n    data_source_name: str | None = None,\n) -&gt; \"OracleConnector\"\n</code></pre> <p>Use this function to create a new Oracle connector.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>User to connect to the database.</p> required <code>password</code> <code>str</code> <p>Password to uso to connect to the database.</p> required <code>host</code> <code>str | None</code> <p>Host of the database.</p> <code>None</code> <code>service</code> <code>str | None</code> <p>Service name of the database.</p> <code>None</code> <code>port</code> <code>int</code> <p>Port of the database.</p> <code>1521</code> <code>data_source_name</code> <code>str | None</code> <p>DSN connection string to connect on the database.  Observe that if DSN is provided, then host, service and port are ignored.</p> <code>None</code> <p>Returns:</p> Type Description <code>'OracleConnector'</code> <p>Oracle connector.</p> Source code in <code>src/hamana/connector/db/oracle.py</code> <pre><code>@classmethod\ndef new(\n    cls,\n    user: str,\n    password: str,\n    host: str | None = None,\n    service: str | None = None,\n    port: int = 1521,\n    data_source_name: str | None = None\n) -&gt; \"OracleConnector\":\n    \"\"\"\n        Use this function to create a new Oracle connector.\n\n        Parameters:\n            user: User to connect to the database.\n            password: Password to uso to connect to the database.\n            host: Host of the database.\n            service: Service name of the database.\n            port: Port of the database.\n            data_source_name: DSN connection string to connect on the database. \n                Observe that if DSN is provided, then host, service and port are ignored.\n\n        Returns:\n            Oracle connector.\n    \"\"\"\n    logger.debug(\"start\")\n    config = cls.create_config(\n        user = user,\n        password = password,\n        host = host,\n        service = service,\n        port = port,\n        data_source_name = data_source_name\n    )\n    logger.debug(\"end\")\n    return cls(config)\n</code></pre>"},{"location":"connector/db/sqlite.html","title":"SQLite","text":"<p>To connect to an SQLite database, is possible to import the <code>SQLiteConnector</code> class from the <code>hamana.connector.db.sqlite</code> module. As a shortcut, the <code>SQLiteConnector</code> class is also available in the <code>hamana.connector.db</code> module as <code>SQLite</code>.</p> <pre><code>import hamana as hm\n\n# connect database\nsqlite_db = hm.connector.db.SQLite(\"database.db\")\n\n# perform operations\n# ...\n</code></pre>"},{"location":"connector/db/sqlite.html#hamana.connector.db.sqlite","title":"hamana.connector.db.sqlite","text":""},{"location":"connector/db/sqlite.html#hamana.connector.db.sqlite.SQLiteConnector","title":"SQLiteConnector","text":"<pre><code>SQLiteConnector(path: str, **kwargs: dict[str, Any])\n</code></pre> <p>               Bases: <code>BaseConnector</code></p> <p>Class representing a connector to a SQLite database.</p> Source code in <code>src/hamana/connector/db/sqlite.py</code> <pre><code>def __init__(self, path: str, **kwargs: dict[str, Any]) -&gt; None:\n    self.path = path\n    self.kwargs = kwargs\n    self.connection: Connection\n</code></pre>"},{"location":"connector/db/teradata.html","title":"Teradata","text":"<p>To connect to a Teradata database, is possible to import the <code>TeradataConnector</code> class from the <code>hamana.connector.db.teradata</code> module. As a shortcut, the <code>TeradataConnector</code> class is also available in the <code>hamana.connector.db</code> module as <code>Teradata</code>.</p> <pre><code>import hamana as hm\n\n# connect database\nteradata_db = hm.connector.db.Teradata(\n    host = \"localhost\",\n    port = 1025,\n    user = \"user\",\n    password = \"password\"\n)\n\n# perform operations\n# ...\n</code></pre>"},{"location":"connector/db/teradata.html#hamana.connector.db.teradata","title":"hamana.connector.db.teradata","text":""},{"location":"connector/db/teradata.html#hamana.connector.db.teradata.TeradataConnector","title":"TeradataConnector","text":"<pre><code>TeradataConnector(\n    user: str | None = None,\n    password: str | None = None,\n    host: str | None = None,\n    database: str | None = None,\n    port: int = 1025,\n    logmech: str = \"LDAP\",\n    **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>BaseConnector</code></p> <p>Class representing a connector to a Teradata database.</p> <p>Initialize the Teradata connector with the given parameters. Teradata provides a whole range of options to configure the connection  with the database, see <code>teradatasql</code> Documentation. For this reasons, the most common parameters can be passed directly to the constructor,  while all others can be specified directly as keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str | None</code> <p>username to connect to the database.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>password to connect to the database.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>hostname or IP address of the Teradata database.</p> <code>None</code> <code>database</code> <code>str | None</code> <p>name of the database to connect to.</p> <code>None</code> <code>port</code> <code>int</code> <p>port of the Teradata database. Default is 1025.</p> <code>1025</code> <code>logmech</code> <code>str</code> <p>logon mechanism to use for the connection. Default is \"LDAP\".</p> <code>'LDAP'</code> <code>**kwargs</code> <code>Any</code> <p>additional keyword arguments to pass to the Teradata connection.</p> <code>{}</code> Source code in <code>src/hamana/connector/db/teradata.py</code> <pre><code>def __init__(\n    self,\n    user: str | None = None,\n    password: str | None = None,\n    host: str | None = None,\n    database: str | None = None,\n    port: int = 1025,\n    logmech: str = \"LDAP\",\n    **kwargs: Any\n) -&gt; None:\n    \"\"\"\n        Initialize the Teradata connector with the given parameters.  \n        Teradata provides a whole range of options to configure the connection \n        with the database, see `teradatasql` [Documentation](https://github.com/Teradata/python-driver).  \n        For this reasons, the most common parameters can be passed directly to the constructor, \n        while all others can be specified directly as keyword arguments.\n\n        Parameters:\n            user: username to connect to the database.\n            password: password to connect to the database.\n            host: hostname or IP address of the Teradata database.\n            database: name of the database to connect to.\n            port: port of the Teradata database. Default is 1025.\n            logmech: logon mechanism to use for the connection. Default is \"LDAP\".\n            **kwargs: additional keyword arguments to pass to the Teradata connection.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # commons\n    self.user = user\n    self.password = password\n    self.host = host\n    self.database = database\n    self.port = port\n    self.logmech = logmech\n\n    # additional parameters\n    self.kwargs = kwargs\n\n    # connection\n    self.connection: Connection\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/file/index.html","title":"File Connectors","text":"<p>The <code>hamana.connector.file</code> package provides a set of connectors to interact with files data sources (CSV, Excel, etc.). The package is designed to be extensible and easy to use.</p> <p>Due to the variety of file formats, it is difficult to provide a common interface for all the connectors. However, the connectors should provide at least the following methods:</p> <ul> <li><code>execute</code>: read the entire content of the file and store it in memory. Usually, the method returns a Query object with the results stored in the <code>result</code> attribute as a <code>pandas.DataFrame</code>. This approach could be useful for queries that rerturn a limited number of rows.</li> <li><code>batch_execute</code>: similar to <code>execute</code>, but it is designed to handle files with a large number of rows. The function returns a generator that yields the results by a batch of rows.</li> <li><code>to_sqlite</code>: this method read the file and store the results in a dedicated table on the internal <code>hamana</code> SQLite database. This approach is useful to store the results of a query and use them later in the analysis.</li> </ul> <p>The following example shows how to connect to a CSV file and store the content into a table hosted on the internal <code>hamana</code> SQLite database.</p> <pre><code>import hamana as hm\n\n# connect hamana database\nhm.connect()\n\n# connect to the CSV file\norders_csv = hm.connector.file.CSV(\"orders.csv\")\n\n# store content\norders_csv.to_sqlite(table_name = \"orders\", batch_size = 50_000)\n\n# combine data with another table (previously stored in the SQLite database)\ncustomers_orders = hm.execute(\"\"\"\n    SELECT\n          c.customer_name\n        , o.order_date\n        , o.total\n    FROM customers c\n    JOIN orders o ON\n        c.customer_id = o.customer_id\"\"\"\n)\n\n# use `pandas` for further analysis\nprint(customers_orders.result.head())\n\n# disconnect\nhm.disconnect()\n</code></pre> <p>The current available connectors are:</p> Sources Path Connector CSV <code>hamana.connector.file</code> CSV"},{"location":"connector/file/csv.html","title":"CSV","text":"<p>To \"connect\" to a CSV file, is possible to import the <code>CSVConnector</code> class from the <code>hamana.connector.file.csv</code> module. As a shortcut, the <code>CSVConnector</code> class is also available in the <code>hamana.connector.file</code> module as <code>CSV</code>.</p> <pre><code>import hamana as hm\n\n# connect\ncustomers_csv = hm.connector.file.CSV(\"customers.csv\")\ncustomers = customers.execute()\n\n# perform operations\n# ...\n</code></pre>"},{"location":"connector/file/csv.html#hamana.connector.file.csv","title":"hamana.connector.file.csv","text":""},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector","title":"CSVConnector","text":"<pre><code>CSVConnector(\n    file_path: str | Path,\n    dialect: type[csv.Dialect] | None = None,\n    has_header: bool | None = None,\n    columns: list[Column] | None = None,\n    encoding: str = getencoding(),\n)\n</code></pre> <p>Class representing the connector to a CSV file.  </p> <p>Observe that when the object is initialized, the class is not going to read the CSV file; the class only performs checks on the file  and extract metadata.</p> <p>To process the CSV file, use the methods <code>execute()</code> or <code>to_sqlite()</code>.</p> <p>Example: <pre><code>import hamana as hm\n\ncsv_file = hm.connector.file.CSV('path/to/file.csv')\nquery = csv_file.execute()\n\nprint(query.result.head())\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the CSV file.</p> required <code>dialect</code> <code>type[csv.Dialect] | None</code> <p>Dialect of the CSV file; the dialect is a class that defines  the parameters for reading and writing CSV files, such as the  delimiter, quotechar, and quoting. Commonly used dialects are:     <code>csv.excel</code> (the dialect to use for CSV generated by Excel.),      <code>csv.excel_tab</code>(the dialect to use for tab-delimited files that are generated by Excel.),      <code>csv.unix_dialect</code> (the dialect to use for Unix-style CSV files.). If <code>None</code>, the class will try to infer the dialect of the CSV  file by using the <code>csv.Sniffer.sniff()</code> method.</p> <code>None</code> <code>has_header</code> <code>bool | None</code> <p>Flag to indicate if the CSV file has a header. If <code>None</code>, the class will try to infer it; observe  that this method could lead to false positives.</p> <code>None</code> <code>columns</code> <code>list[Column] | None</code> <p>List of columns in the CSV file.  If columns are provided, ensure to list all the columns.  By default, the class will try to infer the columns directly from  the file. If the header is not available, then by default, the  names of the columns will be <code>column_1</code>, <code>column_2</code>, and so on.  The data type of the columns will be inferred automatically  by taking a sample of 1000 rows from the file, converted into a  DataFrame, and using the data types from the DataFrame.</p> <code>None</code> <code>encoding</code> <code>str</code> <p>Define the encoding to use during the reading process of the file. By default, the class uses the system encoding retrieved by the <code>locale.getencoding()</code> method.</p> <code>getencoding()</code> Source code in <code>src/hamana/connector/file/csv.py</code> <pre><code>def __init__(\n    self,\n    file_path: str | Path,\n    dialect: type[csv.Dialect] | None = None,\n    has_header: bool | None = None,\n    columns: list[Column] | None = None,\n    encoding: str = getencoding()\n) -&gt; None:\n    logger.debug(\"start\")\n\n    self.file_path = Path(file_path)\n    logger.debug(f\"file_path: {self.file_path}\")\n\n    self.encoding = encoding\n    logger.debug(f\"encoding: {self.encoding}\")\n\n    # check file existance\n    if not self.file_path.exists():\n        error_msg = f\"File not found: {self.file_path}\"\n        logger.error(error_msg)\n        raise FileNotFoundError(error_msg)\n\n    # set file name\n    self.file_name = self.file_path.name\n    logger.debug(f\"file_name: {self.file_name}\")\n\n    # set dialect\n    infer_dialect = self._infer_dialect()\n    if dialect is None:\n        logger.info(\"dialect is not provided, trying to infer..\")\n        self.dialect = infer_dialect\n    else:\n        # compare dialect with inferred dialect\n        self._compare_dialects(dialect, infer_dialect)\n        self.dialect = dialect\n\n    # set has_header\n    if has_header is None:\n        logger.info(\"has_header is not provided, trying to infer..\")\n        has_header = self._check_has_header()\n    self.has_header = has_header\n    logger.debug(f\"has_header: {self.has_header}\")\n\n    # set columns\n    infer_columns = self._infer_columns()\n    self.columns = self._compute_columns(infer_columns, columns)\n    logger.debug(f\"columns: {[column.name for column in self.columns]}\")\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.dialect","title":"dialect  <code>instance-attribute</code>","text":"<pre><code>dialect: type[csv.Dialect]\n</code></pre> <p>Dialect of the CSV file.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.file_path","title":"file_path  <code>instance-attribute</code>","text":"<pre><code>file_path: Path = Path(file_path)\n</code></pre> <p>Path and name of the CSV file.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.encoding","title":"encoding  <code>instance-attribute</code>","text":"<pre><code>encoding: str = encoding\n</code></pre> <p>Encoding to use during the reading process of the file.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.file_name","title":"file_name  <code>instance-attribute</code>","text":"<pre><code>file_name: str = self.file_path.name\n</code></pre> <p>Name of the CSV file.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.has_header","title":"has_header  <code>instance-attribute</code>","text":"<pre><code>has_header: bool = has_header\n</code></pre> <p>Flag to indicate if the CSV file has a header.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.columns","title":"columns  <code>instance-attribute</code>","text":"<pre><code>columns: list[Column] = self._compute_columns(\n    infer_columns, columns\n)\n</code></pre> <p>List of columns in the CSV file.</p>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.execute","title":"execute","text":"<pre><code>execute() -&gt; Query\n</code></pre> <p>Function used to extract data from the CSV file.</p> <p>Returns:</p> Type Description <code>Query</code> <p>The function automatically creates a <code>Query</code> object,  executes the extraction and returns the object created with the resulting rows.</p> Source code in <code>src/hamana/connector/file/csv.py</code> <pre><code>def execute(self) -&gt; Query:\n    \"\"\"\n        Function used to extract data from the CSV file.\n\n        Returns:\n            The function automatically creates a `Query` object, \n                executes the extraction and returns the object created\n                with the resulting rows.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # set query\n    query = Query(\n        query = f\"SELECT * FROM '{self.file_name}'\",\n        columns = self.columns\n    )\n    logger.info(f\"query created: {query.query}\")\n\n    # read CSV file\n    logger.debug(\"reading CSV file\")\n    df_result = pd.read_csv(\n        filepath_or_buffer = self.file_path,\n        dialect = self.dialect, # type: ignore\n        header = 0 if self.has_header else None,\n        names = [column.name for column in self.columns],\n        encoding = self.encoding,\n        dtype = \"object\"\n    )\n    logger.info(f\"data extracted, rows: {df_result.shape[0]}, columns: {df_result.shape[1]}\")\n\n    # adjust columns\n    logger.debug(\"adjusting columns and data types\")\n    df_result = query.adjust_df(df_result)\n\n    # set result\n    query.result = df_result\n\n    logger.debug(\"end\")\n    return query\n</code></pre>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.batch_execute","title":"batch_execute","text":"<pre><code>batch_execute(\n    batch_size: int,\n) -&gt; Generator[list[list], None, None]\n</code></pre> <p>Function used to extract data from the CSV file and return the results in batches.  This approach is used to avoid memory issues when dealing with large datasets.</p> <p>Observe that the returned data are not adjusted in terms of data types, but  provided as raw data.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>size of the batch to return.</p> required <p>Returns:</p> Type Description <code>None</code> <p>Generator used to return the results in batches.</p> Source code in <code>src/hamana/connector/file/csv.py</code> <pre><code>def batch_execute(self, batch_size: int) -&gt; Generator[list[list], None, None]:\n    \"\"\"\n        Function used to extract data from the CSV file and return the results in batches. \n        This approach is used to avoid memory issues when dealing with large datasets.\n\n        Observe that the returned data are not adjusted in terms of data types, but \n        provided as raw data.\n\n        Parameters:\n            batch_size: size of the batch to return.\n\n        Returns:\n            Generator used to return the results in batches.\n    \"\"\"\n    logger.debug(\"start\")\n    logger.debug(f\"batch size: {batch_size}\")\n\n    # open file\n    dt_start = datetime.now()\n    logger.debug(f\"open file {self.file_path}\")\n    with open(self.file_path, \"r\", newline = \"\", encoding = self.encoding) as file:\n        reader = csv.reader(file, dialect = self.dialect)\n\n        # skip header\n        if self.has_header:\n            logger.debug(\"header skipped\")\n            next(reader)\n\n        # read rows\n        batch = []\n        row_count = 1\n        batch_count = 1\n\n        try:\n            for row in reader:\n                batch.append(row)\n                row_count += 1\n                if len(batch) == batch_size:\n                    if batch_count % 100 == 0:\n                        logger.info(f\"batch {batch_count} read\")\n                    yield batch\n\n                    # reset batch\n                    batch = []\n                    batch_count += 1\n        except UnicodeDecodeError as e:\n            err_msg = f\"ERROR: parsing {row_count + 1} row.\"\n            logger.error(err_msg)\n            logger.exception(e)\n            raise CSVDecodeRowError(err_msg)\n\n        # yield remaining rows\n        if len(batch) &gt; 0:\n            yield batch\n\n    dt_end = datetime.now()\n    logger.info(f\"file read, elapsed time: {dt_end - dt_start}\")\n    logger.info(f\"{row_count} rows processed ({batch_count} batches)\")\n    logger.debug(\"end\")\n</code></pre>"},{"location":"connector/file/csv.html#hamana.connector.file.csv.CSVConnector.to_sqlite","title":"to_sqlite","text":"<pre><code>to_sqlite(\n    table_name: str,\n    raw_insert: bool = False,\n    batch_size: int = 10000,\n    mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE,\n) -&gt; None\n</code></pre> <p>This function is used to extract data from the CSV file and  insert it into the <code>hamana</code> internal database (<code>HamanaConnector</code>).</p> <p>The <code>hamana</code> db is a SQLite database, for this reason  <code>bool</code>, <code>datetime</code> and <code>timestamp</code> data types are not supported. If some of the columns are defined with these data types,  then the method could perform an automatic conversion to  a SQLite data type.</p> <p>The conversions are:</p> <ul> <li><code>bool</code> columns are mapped to <code>INTEGER</code> data type, with the values      <code>True</code> and <code>False</code> converted to <code>1</code> and <code>0</code>.</li> <li><code>datetime</code> columns are mapped to <code>REAL</code> data type, with the values      converted to a float number using the following format: <code>YYYYMMDD.HHmmss</code>.     Observe that the integer part represents the date in the format <code>YYYYMMDD</code>,     while the decimal part represents the time component in the format <code>HHmmss</code>.</li> </ul> <p>By default, the method performs the automatic datatype  conversion. However, use the parameter <code>raw_insert</code> to  avoid this conversion and improve the INSERT efficiency. </p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of the table to insert the data. By assumption, the table's name is converted to uppercase.</p> required <code>raw_insert</code> <code>bool</code> <p>bool value to disable/activate the datatype  conversion during the INSERT process. By default, it is  set to <code>False</code>.</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>size of the batch used during the inserting process.</p> <code>10000</code> <code>mode</code> <code>SQLiteDataImportMode</code> <p>mode of importing the data into the database.</p> <code>SQLiteDataImportMode.REPLACE</code> Source code in <code>src/hamana/connector/file/csv.py</code> <pre><code>def to_sqlite(\n    self,\n    table_name: str,\n    raw_insert: bool = False,\n    batch_size: int = 10_000,\n    mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE\n) -&gt; None:\n    \"\"\"\n        This function is used to extract data from the CSV file and \n        insert it into the `hamana` internal database (`HamanaConnector`).\n\n        The `hamana` db is a SQLite database, for this reason \n        `bool`, `datetime` and `timestamp` data types are not supported.\n        If some of the columns are defined with these data types, \n        then the method could perform an automatic conversion to \n        a SQLite data type.\n\n        The conversions are:\n\n        - `bool` columns are mapped to `INTEGER` data type, with the values \n            `True` and `False` converted to `1` and `0`.\n        - `datetime` columns are mapped to `REAL` data type, with the values \n            converted to a float number using the following format: `YYYYMMDD.HHmmss`.\n            Observe that the integer part represents the date in the format `YYYYMMDD`,\n            while the decimal part represents the time component in the format `HHmmss`.\n\n        By default, the method performs the automatic datatype \n        conversion. However, use the parameter `raw_insert` to \n        **avoid** this conversion and improve the INSERT efficiency. \n\n        Parameters:\n            table_name: name of the table to insert the data.\n                By assumption, the table's name is converted to uppercase.\n            raw_insert: bool value to disable/activate the datatype \n                conversion during the INSERT process. By default, it is \n                set to `False`.\n            batch_size: size of the batch used during the inserting process.\n            mode: mode of importing the data into the database.\n    \"\"\"\n    logger.debug(\"start\")\n\n    table_name_upper = table_name.upper()\n    insert_query: str = \"\"\n    column_names: list[str] = []\n    query = Query(\n        query = f\"SELECT * FROM '{self.file_name}'\",\n        columns = self.columns\n    )\n\n    # import internal database\n    from ..db.hamana import HamanaConnector\n    logger.debug(\"imported internal database\")\n\n    # get instance\n    hamana_db = HamanaConnector.get_instance()\n    hamana_connection = hamana_db.get_connection()\n    logger.debug(\"internal database instance obtained\")\n\n    # check table existance\n    query_check_table = Query(\n        query = \"\"\"SELECT COUNT(1) AS flag_exists FROM sqlite_master WHERE type = 'table' AND name = :table_name\"\"\",\n        params = {\"table_name\": table_name_upper},\n        columns = [\n            BooleanColumn(order = 0, name = \"flag_exists\", true_value = 1, false_value = 0)\n        ]\n    )\n    hamana_db.execute(query_check_table)\n    logger.debug(\"table check query executed\")\n\n    flag_table_exists = False\n    if query_check_table.result is not None:\n        flag_table_exists = query_check_table.result[\"flag_exists\"].values[0]\n    logger.info(f\"table exists: {flag_table_exists}\")\n\n    # block insert if mode is fail and table exists\n    if flag_table_exists and mode == SQLiteDataImportMode.FAIL:\n        logger.error(f\"table {table_name_upper} already exists\")\n        raise TableAlreadyExists(table_name_upper)\n\n    # execute extraction\n    logger.info(f\"extracting data, batch size: {batch_size}\")\n    flag_first_batch = True\n    hamana_cursor = hamana_connection.cursor()\n    for raw_batch in self.batch_execute(batch_size):\n\n        if flag_first_batch:\n            logger.info(\"generating insert query\")\n            insert_query = query.get_insert_query(table_name_upper)\n            column_names = query.get_column_names()\n\n            # create table\n            if not flag_table_exists or mode == SQLiteDataImportMode.REPLACE:\n\n                # drop if exists (for replace)\n                if flag_table_exists:\n                    logger.info(f\"drop table {table_name_upper}\")\n                    hamana_cursor.execute(f\"DROP TABLE {table_name_upper}\")\n                    hamana_connection.commit()\n                    logger.debug(\"table dropped\")\n\n                logger.info(f\"creating table {table_name_upper}\")\n                hamana_cursor.execute(query.get_create_query(table_name_upper))\n                hamana_connection.commit()\n                logger.debug(\"table created\")\n\n            # set flag\n            flag_first_batch = False\n\n        # adjust data types\n        if raw_insert:\n            # no data type conversion\n            hamana_cursor.executemany(insert_query, raw_batch)\n            hamana_connection.commit()\n        else:\n            # create temporary query\n            query_temp = Query(query = query.query, columns = query.columns)\n\n            # assign result (adjust data types)\n            df_temp = pd.DataFrame(raw_batch, columns = column_names)\n            df_temp = query_temp.adjust_df(df_temp)\n            query_temp.result = df_temp\n\n            # insert into table\n            query_temp.to_sqlite(table_name_upper, SQLiteDataImportMode.APPEND)\n\n    logger.info(f\"data inserted into table {table_name_upper}\")\n    hamana_cursor.close()\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"connector/file/exceptions.html","title":"Exceptions and Warnings","text":"<p>This section is dedicated present the exceptions and warnings related to file connectors.</p>"},{"location":"connector/file/exceptions.html#hamana.connector.file.exceptions","title":"hamana.connector.file.exceptions","text":""},{"location":"connector/file/exceptions.html#hamana.connector.file.exceptions.CSVColumnNumberMismatchError","title":"CSVColumnNumberMismatchError","text":"<pre><code>CSVColumnNumberMismatchError(description)\n</code></pre> <p>               Bases: <code>HamanaException</code></p> <p>Error when the number of columns in the CSV file does not match the number of columns in the schema.</p> Source code in <code>src/hamana/core/exceptions.py</code> <pre><code>def __init__(self, description):\n    self.description = description\n</code></pre>"},{"location":"connector/file/exceptions.html#hamana.connector.file.exceptions.CSVDecodeRowError","title":"CSVDecodeRowError","text":"<pre><code>CSVDecodeRowError(description)\n</code></pre> <p>               Bases: <code>HamanaException</code></p> <p>Error when decoding a row from the CSV file.</p> Source code in <code>src/hamana/core/exceptions.py</code> <pre><code>def __init__(self, description):\n    self.description = description\n</code></pre>"},{"location":"connector/file/exceptions.html#hamana.connector.file.warnings","title":"hamana.connector.file.warnings","text":""},{"location":"connector/file/exceptions.html#hamana.connector.file.warnings.DialectMismatchWarning","title":"DialectMismatchWarning","text":"<pre><code>DialectMismatchWarning(description)\n</code></pre> <p>               Bases: <code>HamanaWarning</code></p> <p>Warning when the provided dialect does not match the inferred dialect.</p> Source code in <code>src/hamana/core/warnings.py</code> <pre><code>def __init__(self, description):\n    self.description = description\n</code></pre>"},{"location":"core/column.html","title":"Columns","text":"<p>Due to its nature, <code>hamana</code> library is designed to work with data often extracted in tabular form. As a consequence, it was introduced the <code>Column</code> class that could be used to store useful information about the data extracted (e.g. name, type, etc.) and better describe the data. For example, the <code>Column</code> class can be found in <code>Query</code> objects, or in the definition of <code>CSV</code> connectors.</p> <p>Even if <code>Column</code> classes define a general behavior, they can be customized to better fit to specific data types or sources. <code>hamana</code> provides default implemntations for the most common data types:</p> <ul> <li><code>NumberColumn</code>: this column can be used to manage any kind of number.</li> <li><code>IntegerColumn</code>: column class specialised to manage integer values.</li> <li><code>StringColumn</code>: column class specialised to manage string values.</li> <li><code>BooleanColumn</code>: column class specialised to manage boolean values.</li> <li><code>DatetimeColumn</code>: this column is specific for datetime values.</li> <li><code>DateColumn</code>: this column is specific for date values.</li> </ul> <p>These classes could be useful because they provide already a default implementation of the <code>ColumnParser</code> class, that is used to convert the data from the source to the internal representation. In addition, they provide additional class attributes fitting the desired datatype.</p> <p>Clearly, it remains always possible to create custom <code>Column</code> classes by extending the <code>Column</code> class and providing a custom implementation of the <code>ColumnParser</code> class.</p>"},{"location":"core/column.html#datatype","title":"DataType","text":"<p>Before presenting the <code>Column</code> class, we first introduce the <code>DataType</code> class. This class creates a standard inside the library to manage the types, and it provides a bridge between SQLite and <code>pandas</code> data types.</p>"},{"location":"core/column.html#hamana.core.column.DataType","title":"hamana.core.column.DataType","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration representing the datatypes of the <code>hamana</code> columns.</p> <p>The library supports the following data types:</p> <ul> <li><code>INTEGER</code>: integer data type.</li> <li><code>NUMBER</code>: number data type.</li> <li><code>STRING</code>: string data type.</li> <li><code>BOOLEAN</code>: boolean data type.</li> <li><code>DATETIME</code>: datetime data type.</li> <li><code>DATE</code>: date data type.</li> <li><code>CUSTOM</code>: custom data type.</li> </ul> <p>The <code>CUSTOM</code> data type is used to represent a custom datatype  that could be used for dedicated implementations.</p> <p>Since the library is designed to be used with <code>pandas</code> and <code>sqlite</code>,  the <code>DataType</code> enumeration also provides a method to map the data types  to the corresponding data types in <code>sqlite</code> and <code>pandas</code>.</p>"},{"location":"core/column.html#hamana.core.column.DataType.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = 'integer'\n</code></pre> <p>Integer data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.NUMBER","title":"NUMBER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NUMBER = 'number'\n</code></pre> <p>Number data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.STRING","title":"STRING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STRING = 'string'\n</code></pre> <p>String data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.BOOLEAN","title":"BOOLEAN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BOOLEAN = 'boolean'\n</code></pre> <p>Boolean data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.DATETIME","title":"DATETIME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DATETIME = 'datetime'\n</code></pre> <p>Datetime data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.DATE","title":"DATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DATE = 'date'\n</code></pre> <p>Date data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.CUSTOM","title":"CUSTOM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CUSTOM = 'custom'\n</code></pre> <p>Custom data type.</p>"},{"location":"core/column.html#hamana.core.column.DataType.from_pandas","title":"from_pandas  <code>classmethod</code>","text":"<pre><code>from_pandas(dtype: str) -&gt; DataType\n</code></pre> <p>Function to map a <code>pandas</code> datatype to <code>DataType</code>.</p> <p>Observe that if no mapping is found, the default is <code>DataType.STRING</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>str</code> <p>pandas data type.</p> required <p>Returns:</p> Type Description <code>DataType</code> <p><code>DataType</code> mapped.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>@classmethod\ndef from_pandas(cls, dtype: str) -&gt; \"DataType\":\n    \"\"\"\n        Function to map a `pandas` datatype to `DataType`.\n\n        Observe that if no mapping is found, the default is `DataType.STRING`.\n\n        Parameters:\n            dtype: pandas data type.\n\n        Returns:\n            `DataType` mapped.\n    \"\"\"\n    if \"int\" in dtype:\n        return DataType.INTEGER\n    elif \"float\" in dtype:\n        return DataType.NUMBER\n    elif dtype == \"object\":\n        return DataType.STRING\n    elif dtype == \"bool\":\n        return DataType.BOOLEAN\n    elif \"datetime\" in dtype:\n        return DataType.DATETIME\n    else:\n        logger.warning(f\"unknown data type: {dtype}\")\n        return DataType.STRING\n</code></pre>"},{"location":"core/column.html#hamana.core.column.DataType.to_sqlite","title":"to_sqlite  <code>classmethod</code>","text":"<pre><code>to_sqlite(dtype: DataType) -&gt; str\n</code></pre> <p>Function to map a <code>DataType</code> to a SQLite datatype.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DataType</code> <p><code>DataType</code> to be mapped.</p> required <p>Returns:</p> Type Description <code>str</code> <p>SQLite data type mapped.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>@classmethod\ndef to_sqlite(cls, dtype: \"DataType\") -&gt; str:\n    \"\"\"\n        Function to map a `DataType` to a SQLite datatype.\n\n        Parameters:\n            dtype: `DataType` to be mapped.\n\n        Returns:\n            SQLite data type mapped.\n    \"\"\"\n    match dtype:\n        case DataType.INTEGER:\n            return \"INTEGER\"\n        case DataType.NUMBER:\n            return \"REAL\"\n        case DataType.STRING:\n            return \"TEXT\"\n        case DataType.BOOLEAN:\n            return \"INTEGER\"\n        case DataType.DATETIME:\n            return \"INTEGER\"\n        case DataType.DATE:\n            return \"INTEGER\"\n        case DataType.CUSTOM:\n            return \"BLOB\"\n        case _:\n            return \"\"\n</code></pre>"},{"location":"core/column.html#parser","title":"Parser","text":"<p>Another useful functionality that could be available in the <code>Column</code> class is the <code>parser</code> attribute. This variable, if present, is an instance of the <code>ColumnParser</code> class, that is used to convert the data from the source to the internal representation.</p> <p>The <code>ColumnParser</code> class is composed of two methods:</p> <ul> <li><code>pandas</code>: this method must respect the protocol <code>PandasParser</code>, and it is specifically used to convert <code>pandas.Series</code> input datas.</li> <li><code>polars</code>: currently not supported, but it will be used to convert <code>polars.Series</code> input datas.</li> </ul> <p>By default, the <code>Column</code> class does not provide any parser, but the <code>NumberColumn</code>, <code>IntegerColumn</code>, <code>StringColumn</code>, <code>BooleanColumn</code>, <code>DatetimeColumn</code>, and <code>DateColumn</code> classes provide a default implementation of the <code>ColumnParser</code> class.</p>"},{"location":"core/column.html#hamana.core.column.ColumnParser","title":"hamana.core.column.ColumnParser  <code>dataclass</code>","text":"<pre><code>ColumnParser(\n    pandas: PandasParser, polars: Callable | None = None\n)\n</code></pre> <p>Class representing a parser for a column in the <code>hamana</code> library.</p> <p>Since the library is designed to be used with <code>pandas</code> and <code>polars</code>,  the <code>ColumnParser</code> class provides methods that could be used to parse  data coming from these libraries.</p>"},{"location":"core/column.html#hamana.core.column.PandasParser","title":"hamana.core.column.PandasParser","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol representing a parser for <code>pandas</code> series.</p> <p>A <code>pandas</code> parser is a function that requires at least a <code>pandas</code> series  to be taken as input and returned as output after dedicated transformations.</p> <p>Structure: <pre><code>def parser(series: pandas.Series, *args: Any, **kwargs: Any) -&gt; pandas.Series:\n    ...\n</code></pre></p>"},{"location":"core/column.html#identifier","title":"Identifier","text":"<p>The are many situations where it is required to identity the column datatype (string, number, date, etc.), e.g. when the data is extracted from file sources like CSV files. To solve this problem, <code>hamana</code> provides the <code>ColumnIdentifier</code> class, that is used to identify the column type according to an input data.</p> <p>Similarly to the <code>ColumnParser</code> class, the <code>ColumnIdentifier</code> class is composed of two methods:</p> <ul> <li><code>pandas</code>: this method must respect the protocol <code>PandasIdentifier</code>, and it is specifically used to identify the column type from a <code>pandas.Series</code> input data.</li> <li><code>polars</code>: currently not supported, but it will be used to identify the column type from a <code>polars.Series</code> input data.</li> </ul>"},{"location":"core/column.html#hamana.core.identifier.ColumnIdentifier","title":"hamana.core.identifier.ColumnIdentifier  <code>dataclass</code>","text":"<pre><code>ColumnIdentifier(\n    pandas: PandasIdentifier[TColumn],\n    polars: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>Generic[TColumn]</code></p> <p>Class representing an identifier for a column in the <code>hamana</code> library.</p> <p>Since the library is designed to be used with <code>pandas</code> and <code>polars</code>, the <code>ColumnIdentifier</code> class provides methods that could be used to identify the column from a set of data from both libraries.</p> Note <p>Observe that the identification process tries to infer the column type based on the data provided. The process is not perfect and could  lead to wrong inferences. The user should always check the inferred  column type and adjust it if needed.</p>"},{"location":"core/column.html#hamana.core.identifier.ColumnIdentifier.is_empty","title":"is_empty  <code>staticmethod</code>","text":"<pre><code>is_empty(\n    series: PandasSeries, raise_error: bool = False\n) -&gt; bool\n</code></pre> <p>Check if the series is empty.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p>the series to check.</p> required <code>raise_error</code> <code>bool</code> <p>if True, raise an error if the series is empty.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the series is empty, False otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>@staticmethod\ndef is_empty(series: PandasSeries, raise_error: bool = False) -&gt; bool:\n    \"\"\"\n        Check if the series is empty.\n\n        Parameters:\n            series: the series to check.\n            raise_error: if True, raise an error if the series is empty.\n\n        Returns:\n            True if the series is empty, False otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n\n    is_empty = series.empty\n    if is_empty and raise_error:\n        raise ColumnIdentifierEmptySeriesError(\"empty series\")\n\n    logger.debug(\"end\")\n    return is_empty\n</code></pre>"},{"location":"core/column.html#hamana.core.identifier.ColumnIdentifier.__call__","title":"__call__","text":"<pre><code>__call__(\n    series: Any,\n    column_name: str,\n    order: int | None = None,\n    *args: Any,\n    **kwargs: Any\n) -&gt; TColumn | None\n</code></pre> <p>Identifies the column type from a given series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Any</code> <p>the series to identify the column type from.</p> required <code>column_name</code> <code>str</code> <p>the name of the column to identify.</p> required <code>*args</code> <code>Any</code> <p>additional arguments to pass to the identifier.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>additional keyword arguments to pass to the identifier.</p> <code>{}</code> <p>Returns:</p> Type Description <code>TColumn | None</code> <p>the identified column type or <code>None</code> if the column type could not be identified.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def __call__(self, series: Any, column_name: str, order: int | None = None, *args: Any, **kwargs: Any) -&gt; TColumn | None:\n    \"\"\"\n        Identifies the column type from a given series.\n\n        Parameters:\n            series: the series to identify the column type from.\n            column_name: the name of the column to identify.\n            *args: additional arguments to pass to the identifier.\n            **kwargs: additional keyword arguments to pass to the identifier.\n\n        Returns:\n            the identified column type or `None` if the column type\n                could not be identified.\n    \"\"\"\n    logger.debug(\"start\")\n\n    _series = None\n\n    # pandas series\n    if isinstance(series, PandasSeries):\n        try:\n            logging.debug(\"Identifying column type using pandas identifier.\")\n            _series = self.pandas(series, column_name, order, *args, **kwargs)\n        except ColumnDateFormatterError as e:\n            logger.error(\"Column date formatter error.\")\n            logger.exception(e)\n            raise e\n        except Exception as e:\n            logger.info(\"pandas identifier failed.\")\n            logger.exception(e)\n\n    logger.debug(\"end\")\n    return _series\n</code></pre>"},{"location":"core/column.html#hamana.core.identifier.ColumnIdentifier.infer","title":"infer  <code>staticmethod</code>","text":"<pre><code>infer(\n    series: Any,\n    column_name: str,\n    order: int | None = None,\n    *args: Any,\n    **kwargs: Any\n) -&gt; (\n    NumberColumn\n    | IntegerColumn\n    | StringColumn\n    | BooleanColumn\n    | DatetimeColumn\n    | DateColumn\n)\n</code></pre> <p>Infers the column type from a given series. The function passes  the series to the default <code>hamana</code> identifiers in the following order:</p> <ul> <li><code>DatetimeColumn</code></li> <li><code>BooleanColumn</code></li> <li><code>IntegerColumn</code></li> <li><code>NumberColumn</code></li> <li><code>StringColumn</code></li> </ul> <p>in order to infer the column type.</p> Note <p>If the column is empty, then by default the  function assign the <code>STRING</code> datatype.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Any</code> <p>the series to infer the column type from.</p> required <code>*args</code> <code>Any</code> <p>additional arguments to pass to the identifier.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>additional keyword arguments to pass to the identifier.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NumberColumn | IntegerColumn | StringColumn | BooleanColumn | DatetimeColumn | DateColumn</code> <p>the inferred column type.</p> <p>Raises:</p> Type Description <code>ColumnIdentifierError</code> <p>if no column type could be inferred.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>@staticmethod\ndef infer(series: Any, column_name: str, order: int | None = None, *args: Any, **kwargs: Any) -&gt; NumberColumn | IntegerColumn | StringColumn | BooleanColumn | DatetimeColumn | DateColumn:\n    \"\"\"\n        Infers the column type from a given series. The function passes \n        the series to the default `hamana` identifiers in the following\n        order:\n\n        - [`DatetimeColumn`][hamana.core.column.DatetimeColumn]\n        - [`BooleanColumn`][hamana.core.column.BooleanColumn]\n        - [`IntegerColumn`][hamana.core.column.IntegerColumn]\n        - [`NumberColumn`][hamana.core.column.NumberColumn]\n        - [`StringColumn`][hamana.core.column.StringColumn]\n\n        in order to infer the column type.\n\n        Note:\n            If the column is empty, then by default the \n            function assign the `STRING` datatype.\n\n        Parameters:\n            series: the series to infer the column type from.\n            *args: additional arguments to pass to the identifier.\n            **kwargs: additional keyword arguments to pass to the identifier.\n\n        Returns:\n            the inferred column type.\n\n        Raises:\n            ColumnIdentifierError: if no column type could be inferred.\n    \"\"\"\n    logger.debug(\"start\")\n\n    try:\n        # infer date column\n        inferred_column = date_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(f\"date column inferred, format: {inferred_column.format}\")\n            return inferred_column\n\n        # infer datetime column\n        inferred_column = datetime_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(f\"datetime column inferred, format: {inferred_column.format}\")\n            return inferred_column\n\n        # infer boolean column\n        inferred_column = boolean_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(f\"boolean column inferred, true value: {inferred_column.true_value}, false value: {inferred_column.false_value}\")\n            return inferred_column\n\n        # infer integer column\n        inferred_column = integer_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(f\"integer column inferred, decimal separator: {inferred_column.decimal_separator}, thousands separator: {inferred_column.thousands_separator}\")\n            return inferred_column\n\n        # infer number column\n        inferred_column = number_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(f\"number column inferred, decimal separator: {inferred_column.decimal_separator}, thousands separator: {inferred_column.thousands_separator}\")\n            return inferred_column\n\n        # infer string column\n        inferred_column = string_identifier(series, column_name, order, *args, **kwargs)\n        if inferred_column is not None:\n            logger.info(\"string column inferred\")\n            return inferred_column\n    except ColumnIdentifierEmptySeriesError:\n        logger.warning(f\"column '{column_name}' empty, assigned STRING datatype.\")\n        return StringColumn(name = column_name, order = order)\n\n    raise ColumnIdentifierError(\"no column inferred\")\n</code></pre>"},{"location":"core/column.html#hamana.core.identifier.PandasIdentifier","title":"hamana.core.identifier.PandasIdentifier","text":"<p>               Bases: <code>Protocol[TColumn]</code></p> <p>Protocol representing an identifier for <code>pandas</code> series.</p> <p>A <code>PandasIdentifier</code> is a callable that must have at least  the following input parameters:</p> <ul> <li>series: the <code>pandas</code> series to identify the column type from.</li> <li>column_name: the name of the column to identify.</li> </ul> <p>The <code>PandasIdentifier</code> must return a column type or <code>None</code> if the column type could not be identified.</p> <p>Structure <pre><code>def __call__(self, series: PandasSeries, column_name: str, order: int | None = None, *args: Any, **kwargs: Any) -&gt; TColumn | None:\n    ...\n</code></pre></p>"},{"location":"core/column.html#default-identifiers","title":"Default Identifiers","text":"<p><code>hamana</code> provides a set of default identifiers that can be used to identify the default's <code>hamana</code> column types.</p>"},{"location":"core/column.html#number-identifier","title":"Number Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.number_identifier","title":"hamana.core.identifier.number_identifier  <code>module-attribute</code>","text":"<pre><code>number_identifier = ColumnIdentifier[NumberColumn](\n    pandas=_default_numeric_pandas\n)\n</code></pre> <p>Default identifier for the <code>NumberColumn</code> class.</p> <p>More details on the default methods can be found in  the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_numeric_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_numeric_pandas","title":"hamana.core.identifier._default_numeric_pandas","text":"<pre><code>_default_numeric_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n) -&gt; NumberColumn | None\n</code></pre> <p>This function defines the default behavior to identify a number column from a <code>pandas</code> series.</p> <p>In order to identify a number column, the function follows the steps:</p> <ul> <li>Drop null values (included empty strings)</li> <li>Check if the column has letters</li> <li>Count the max appearance of the comma and dot      separators in all the elements.</li> <li>Evaluate first the default configuration (dot decimal separator,      comma thousands separator).</li> <li>If the default configuration does not work, evaluate the      alternative configuration (comma decimal separator, dot      thousands separator).</li> <li>If also this configuration does not work, return None.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <p>Returns:</p> Type Description <code>NumberColumn | None</code> <p><code>NumberColumn</code> if the column is a number column, <code>None</code> otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_numeric_pandas(series: PandasSeries, column_name: str, order: int | None = None) -&gt; NumberColumn | None:\n    \"\"\"\n        This function defines the default behavior to identify a number column from a `pandas` series.\n\n        In order to identify a number column, the function follows the steps:\n\n        - Drop null values (included empty strings)\n        - Check if the column has letters\n        - Count the max appearance of the comma and dot \n            separators in all the elements.\n        - Evaluate first the default configuration (dot decimal separator, \n            comma thousands separator).\n        - If the default configuration does not work, evaluate the \n            alternative configuration (comma decimal separator, dot \n            thousands separator).\n        - If also this configuration does not work, return None.\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n\n        Returns:\n            `NumberColumn` if the column is a number column, `None` otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna().astype(\"str\")\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n    ColumnIdentifier.is_empty(_series, raise_error = True)\n\n    # check letters presence\n    logger.debug(\"check letters\")\n    if _series.str.replace(r\"[0-9\\.\\-\\+\\,eE]\", \"\", regex = True).str.len().sum() &gt; 0:\n        logger.warning(\"letters found, no number column\")\n        return None\n\n    # check separators\n    comma_separator_count = _series.str.replace(r\"[0-9\\.\\-\\+eE]\", \"\", regex = True).str.len().max()\n    logger.debug(f\"comma separator count: {comma_separator_count}\")\n\n    dot_separator_count   = _series.str.replace(r\"[0-9\\-\\+\\,eE]\", \"\", regex = True).str.len().max()\n    logger.debug(f\"dot separator count: {dot_separator_count}\")\n\n    if (\n            dot_separator_count in [0, 1]\n        and _series.str.match(r\"^[+-]?(\\d+(\\,\\d{3})*|\\d{1,2})(\\.\\d+)?([eE][+-]?\\d+)?$\").all()\n    ):\n        logger.info(\"possible number column: dot decimal separator, comma thousands separator\")\n        column = NumberColumn(name = column_name, decimal_separator = \".\", thousands_separator = \",\", order = order)\n        column.inferred = True\n    elif (\n            comma_separator_count in [0, 1]\n        and _series.str.match(r\"^[+-]?(\\d+(\\.\\d{3})*|\\d{1,2})(\\,\\d+)?([eE][+-]?\\d+)?$\").all()\n    ):\n        logger.info(\"possible number column: comma decimal separator, dot thousands separator\")\n        column = NumberColumn(name = column_name, decimal_separator = \",\", thousands_separator = \".\", order = order)\n        column.inferred = True\n    else:\n        logger.warning(\"no separator found\")\n\n    logger.debug(\"end\")\n    return column\n</code></pre>"},{"location":"core/column.html#integer-identifier","title":"Integer Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.integer_identifier","title":"hamana.core.identifier.integer_identifier  <code>module-attribute</code>","text":"<pre><code>integer_identifier = ColumnIdentifier[IntegerColumn](\n    pandas=_default_integer_pandas\n)\n</code></pre> <p>Default identifier for the <code>IntegerColumn</code> class.</p> <p>More details on the default methods can be found in the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_integer_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_integer_pandas","title":"hamana.core.identifier._default_integer_pandas","text":"<pre><code>_default_integer_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n) -&gt; IntegerColumn | None\n</code></pre> <p>This function defines the default behavior to identify an integer column from a <code>pandas</code> series.</p> <p>In order to identify an integer column, the function follows the steps:</p> <ul> <li>Drop null values (included empty strings)</li> <li>Check if the column can be considered as number datatype</li> <li>If the check is passed, then is checked if the column is      composed only by integers (included the sign).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <p>Returns:</p> Type Description <code>IntegerColumn | None</code> <p><code>IntegerColumn</code> if the column is an integer column, <code>None</code> otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_integer_pandas(series: PandasSeries, column_name: str, order: int | None = None) -&gt; IntegerColumn | None:\n    \"\"\"\n        This function defines the default behavior to identify an integer column from a `pandas` series.\n\n        In order to identify an integer column, the function follows the steps:\n\n        - Drop null values (included empty strings)\n        - Check if the column can be considered as number datatype\n        - If the check is passed, then is checked if the column is \n            composed only by integers (included the sign).\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n\n        Returns:\n            `IntegerColumn` if the column is an integer column, `None` otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna().astype(\"str\")\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n\n    # check number column\n    inferred_column = number_identifier.pandas(series, column_name)\n    if inferred_column is None:\n        logger.warning(\"no number column found\")\n        return None\n    logger.debug(\"number column inferred\")\n\n    # adjust series\n    _series = _series.str.replace(r\"\\.0$\", \"\", regex = True)\n\n    # check separators\n    comma_separator_count = _series.str.replace(r\"[0-9\\.\\-\\+eE]\", \"\", regex = True).str.len().max()\n    logger.debug(f\"comma separator count: {comma_separator_count}\")\n\n    dot_separator_count   = _series.str.replace(r\"[0-9\\-\\+\\,eE]\", \"\", regex = True).str.len().max()\n    logger.debug(f\"dot separator count: {dot_separator_count}\")\n\n    # infer thousands separator\n    thousands_separator = inferred_column.thousands_separator\n    decimal_separator = inferred_column.decimal_separator\n    if comma_separator_count &gt;= 0 and dot_separator_count == 0:\n        thousands_separator = \",\"\n        decimal_separator   = \".\"\n    elif dot_separator_count &gt;= 0 and comma_separator_count == 0:\n        thousands_separator = \".\"\n        decimal_separator   = \",\"\n\n    int_regex = rf\"^[+-]?(\\d+(\\{thousands_separator}\" + r\"\\d{3})*|\\d{1,2})$\"\n    if thousands_separator is not None and _series.str.match(int_regex).all():\n        logger.info(\"integer column found\")\n        column = IntegerColumn(name = inferred_column.name, decimal_separator = decimal_separator, thousands_separator = thousands_separator, order = order)\n        column.inferred = True\n    else:\n        logger.warning(\"no integer column found\")\n\n    logger.debug(\"end\")\n    return column\n</code></pre>"},{"location":"core/column.html#string-identifier","title":"String Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.string_identifier","title":"hamana.core.identifier.string_identifier  <code>module-attribute</code>","text":"<pre><code>string_identifier = ColumnIdentifier[StringColumn](\n    pandas=_default_string_pandas\n)\n</code></pre> <p>Default identifier for the <code>StringColumn</code> class.</p> <p>More details on the default methods can be found in the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_string_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_string_pandas","title":"hamana.core.identifier._default_string_pandas","text":"<pre><code>_default_string_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n) -&gt; StringColumn | None\n</code></pre> <p>Function to identify a string column from a <code>pandas</code> series.</p> <p>The function checks if the column is a string column by  converting the column to string type and checking if at least  one value can be considered as string.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <p>Returns:</p> Type Description <code>StringColumn | None</code> <p><code>StringColumn</code> if the column is a string column, <code>None</code> otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_string_pandas(series: PandasSeries, column_name: str, order: int | None = None) -&gt; StringColumn | None:\n    \"\"\"\n        Function to identify a string column from a `pandas` series.\n\n        The function checks if the column is a string column by \n        converting the column to string type and checking if at least \n        one value can be considered as string.\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n\n        Returns:\n            `StringColumn` if the column is a string column, `None` otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna()\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n    ColumnIdentifier.is_empty(_series, raise_error = True)\n\n    # check values\n    logger.debug(\"check values\")\n    if _series.astype(\"str\").str.match(r\"^[A-Za-z\\d\\W]+$\").any():\n        logger.info(\"string column found\")\n        column = StringColumn(name = column_name, order = order)\n        column.inferred = True\n    else:\n        logger.warning(\"no string column found\")\n\n    logger.debug(\"end\")\n    return column\n</code></pre>"},{"location":"core/column.html#boolean-identifier","title":"Boolean Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.boolean_identifier","title":"hamana.core.identifier.boolean_identifier  <code>module-attribute</code>","text":"<pre><code>boolean_identifier = ColumnIdentifier[BooleanColumn](\n    pandas=_default_boolean_pandas\n)\n</code></pre> <p>Default identifier for the <code>BooleanColumn</code> class.</p> <p>More details on the default methods can be found in the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_boolean_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_boolean_pandas","title":"hamana.core.identifier._default_boolean_pandas","text":"<pre><code>_default_boolean_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n    min_count: int = 1000,\n) -&gt; BooleanColumn | None\n</code></pre> <p>This function defines the default behavior to identify a boolean column from a <code>pandas</code> series.</p> <p>To identify a boolean column, the function checks if the column has only two unique values. Observe, that the function does not check if the values are boolean values, but only if the column has two unique values; for this reason the assignment of the <code>True</code> and <code>False</code> values is arbitrary.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <code>min_count</code> <code>int</code> <p>minimum number of elements to consider the column as a boolean column. This parameter is used to avoid wrong inferences when the column has only a few elements.</p> <code>1000</code> <p>Returns:</p> Type Description <code>BooleanColumn | None</code> <p><code>BooleanColumn</code> if the column is a boolean column, <code>None</code> otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_boolean_pandas(series: PandasSeries, column_name: str, order: int | None = None, min_count: int = 1_000) -&gt; BooleanColumn | None:\n    \"\"\"\n        This function defines the default behavior to identify a boolean column from a `pandas` series.\n\n        To identify a boolean column, the function checks if the column has only two unique values.\n        Observe, that the function does not check if the values are boolean values, but only if the\n        column has two unique values; for this reason the assignment of the `True` and `False` values\n        is arbitrary.\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n            min_count: minimum number of elements to consider the column as a boolean column.\n                This parameter is used to avoid wrong inferences when the column has only a few elements.\n\n        Returns:\n            `BooleanColumn` if the column is a boolean column, `None` otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna()\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n    ColumnIdentifier.is_empty(_series, raise_error = True)\n\n    # check values\n    logger.debug(\"check values\")\n    count_disinct = _series.nunique()\n    if count_disinct == 2 and len(_series) &gt; min_count:\n        values = _series.unique()\n        logger.info(f\"boolean column found, unique values: {values}\")\n        column = BooleanColumn(name = column_name, true_value = values[0], false_value = values[1], order = order)\n        column.inferred = True\n    else:\n        logger.warning(f\"no boolean column, unique values: {count_disinct}\")\n\n    logger.debug(\"end\")\n    return column\n</code></pre>"},{"location":"core/column.html#datetime-identifier","title":"Datetime Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.datetime_identifier","title":"hamana.core.identifier.datetime_identifier  <code>module-attribute</code>","text":"<pre><code>datetime_identifier = ColumnIdentifier[DatetimeColumn](\n    pandas=_default_datetime_pandas\n)\n</code></pre> <p>Default identifier for the <code>DatetimeColumn</code> class.</p> <p>More details on the default methods can be found in the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_datetime_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_datetime_pandas","title":"hamana.core.identifier._default_datetime_pandas","text":"<pre><code>_default_datetime_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n    format: str | None = None,\n) -&gt; DatetimeColumn | None\n</code></pre> <p>This function defines the default behavior to identify a datetime column from a <code>pandas</code> series.</p> <p>To identify this type of column, the function removes first the  null values, then tries to apply <code>pandas.to_datetime</code> with a list  of the most common datetime formats. If the column is not  identified, the function tries to apply <code>pandas.to_datetime</code>  without providing any format. Since this last operation could  lead to wrong inferences, the function considers the column as a datetime column only if all the values are converted correctly.</p> <p>Default Formats:</p> <ul> <li><code>YYYY-MM-DD HH:mm:ss</code></li> <li><code>YYYY-MM-DD HH:mm</code></li> <li><code>YYYY-MM-DD</code></li> <li><code>YYYY/MM/DD HH:mm:ss</code></li> <li><code>YYYY/MM/DD HH:mm</code></li> <li><code>YYYY/MM/DD</code></li> <li><code>YYYYMMDD HH:mm:ss</code></li> <li><code>YYYYMMDD HH:mm</code></li> <li><code>YYYYMMDD</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <code>format</code> <code>str | None</code> <p>datetime format used to try to convert the series. If the format is provided, then the default formats are  not used.</p> <code>None</code> <p>Returns:</p> Type Description <code>DatetimeColumn | None</code> <p><code>DatetimeColumn</code> if the column is a datetime column, <code>None</code> otherwise.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_datetime_pandas(series: PandasSeries, column_name: str, order: int | None = None, format: str | None = None) -&gt; DatetimeColumn | None:\n    \"\"\"\n        This function defines the default behavior to identify a datetime column from a `pandas` series.\n\n        To identify this type of column, the function removes first the \n        null values, then tries to apply `pandas.to_datetime` with a list \n        of the most common datetime formats. If the column is **not** \n        identified, the function tries to apply `pandas.to_datetime` \n        without providing any format. Since this last operation could \n        lead to wrong inferences, the function considers the column as\n        a datetime column only if all the values are converted correctly.\n\n        Default Formats:\n\n        - `YYYY-MM-DD HH:mm:ss`\n        - `YYYY-MM-DD HH:mm`\n        - `YYYY-MM-DD`\n        - `YYYY/MM/DD HH:mm:ss`\n        - `YYYY/MM/DD HH:mm`\n        - `YYYY/MM/DD`\n        - `YYYYMMDD HH:mm:ss`\n        - `YYYYMMDD HH:mm`\n        - `YYYYMMDD`\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n            format: datetime format used to try to convert the series.\n                If the format is provided, then the default formats are \n                not used.\n\n        Returns:\n            `DatetimeColumn` if the column is a datetime column, `None` otherwise.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna().astype(\"str\")\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n    ColumnIdentifier.is_empty(_series, raise_error = True)\n\n    # set format\n    format_list: list[str]\n    if format is None:\n        logger.debug(\"no format provided, check most common formats\")\n        format_list = [\n            \"%Y-%m-%d %H:%M:%S\",\n            \"%Y-%m-%d %H:%M\",\n            \"%Y-%m-%d\",\n            \"%Y/%m/%d %H:%M:%S\",\n            \"%Y/%m/%d %H:%M\",\n            \"%Y/%m/%d\",\n            \"%Y%m%d %H:%M:%S\",\n            \"%Y%m%d %H:%M\",\n            \"%Y%m%d\",\n            \"%Y%m%d%H%M%S\"\n        ]\n    else:\n        format_list = [format]\n\n    # check formats\n    logger.debug(\"check datetime formats\")\n    for _format in format_list:\n        try:\n            if pd.to_datetime(_series, errors = \"coerce\", format = _format).notnull().all():\n                logger.info(f\"format '{_format}' used, datetime column found\")\n                column = DatetimeColumn(name = column_name, format = _format, order = order)\n                column.inferred = True\n                return column\n        except Exception:\n            logger.warning(f\"format '{_format}' not recognized\")\n            logger.warning(\"no datetime column found\")\n\n    logger.debug(\"end\")\n    return None\n</code></pre>"},{"location":"core/column.html#date-identifier","title":"Date Identifier","text":""},{"location":"core/column.html#hamana.core.identifier.date_identifier","title":"hamana.core.identifier.date_identifier  <code>module-attribute</code>","text":"<pre><code>date_identifier = ColumnIdentifier[DatetimeColumn](\n    pandas=_default_date_pandas\n)\n</code></pre> <p>Default identifier for the <code>Datetime</code> class.</p> <p>More details on the default methods can be found in the corresponding functions' documentation.</p> <ul> <li>pandas: <code>_default_date_pandas</code></li> <li>polars: <code>None</code> (not implemented)</li> </ul>"},{"location":"core/column.html#hamana.core.identifier._default_date_pandas","title":"hamana.core.identifier._default_date_pandas","text":"<pre><code>_default_date_pandas(\n    series: PandasSeries,\n    column_name: str,\n    order: int | None = None,\n    format: str | None = None,\n) -&gt; DateColumn | None\n</code></pre> <p>This function defines the default behavior to identify a date column from a <code>pandas</code> series.</p> <p>The function leverages on <code>DatetimeColumn</code> deault pandas identifier method  <code>_default_datetime_pandas</code> to identify the column. However, the function  considers only datetime formats that do not contain time information.</p> <p>Default Formats:</p> <ul> <li><code>YYYY-MM-DD</code></li> <li><code>YYYY/MM/DD</code></li> <li><code>YYYYMMDD</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be checked.</p> required <code>column_name</code> <code>str</code> <p>name of the column to be checked.</p> required <code>format</code> <code>str | None</code> <p>date format used to try to convert the series. If the format is provided, then the default formats are  not used. Observe that the format must not contain time information.</p> <code>None</code> <p>Returns:</p> Type Description <code>DateColumn | None</code> <p><code>DateColumn</code> if the column is a datetime column, <code>None</code> otherwise.</p> <p>Raises:</p> Type Description <code>ColumnDateFormatterError</code> <p>if the format is not valid.</p> Source code in <code>src/hamana/core/identifier.py</code> <pre><code>def _default_date_pandas(series: PandasSeries, column_name: str, order: int | None = None, format: str | None = None) -&gt; DateColumn | None:\n    \"\"\"\n        This function defines the default behavior to identify a date column from a `pandas` series.\n\n        The function leverages on `DatetimeColumn` deault pandas identifier method \n        `_default_datetime_pandas` to identify the column. However, the function \n        considers only datetime formats that do not contain time information.\n\n        Default Formats:\n\n        - `YYYY-MM-DD`\n        - `YYYY/MM/DD`\n        - `YYYYMMDD`\n\n        Parameters:\n            series: `pandas` series to be checked.\n            column_name: name of the column to be checked.\n            format: date format used to try to convert the series.\n                If the format is provided, then the default formats are \n                not used. Observe that the format must not contain time\n                information.\n\n        Returns:\n            `DateColumn` if the column is a datetime column, `None` otherwise.\n\n        Raises:\n            ColumnDateFormatterError: if the format is not valid.\n    \"\"\"\n    logger.debug(\"start\")\n    column = None\n\n    # check valid format\n    if format is not None:\n        logger.debug(\"check valid format\")\n        DateColumn.check_format(format)\n\n    # drop null values\n    _series = series.replace(\"\", None).dropna().astype(\"str\")\n    logger.debug(f\"dropped null values: {len(series) - len(_series)}\")\n    ColumnIdentifier.is_empty(_series, raise_error = True)\n\n    # set format\n    format_list: list[str]\n    if format is None:\n        logger.debug(\"no format provided, check most common formats\")\n        format_list = [\n            \"%Y-%m-%d\",\n            \"%Y/%m/%d\",\n            \"%Y%m%d\"\n        ]\n    else:\n        format_list = [format]\n\n    # check formats\n    logger.debug(\"check datetime formats\")\n    for _format in format_list:\n        if _default_datetime_pandas(_series, column_name, order, _format) is not None:\n            logger.info(f\"format '{_format}' used, date column found\")\n            column = DateColumn(name = column_name, format = _format, order = order)\n            column.inferred = True\n\n    logger.debug(\"end\")\n    return column\n</code></pre>"},{"location":"core/column.html#api","title":"API","text":""},{"location":"core/column.html#hamana.core.column.Column","title":"hamana.core.column.Column  <code>dataclass</code>","text":"<pre><code>Column(\n    name: str,\n    dtype: DataType,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n    inferred: bool = False,\n)\n</code></pre> <p>Class representing a column in the <code>hamana</code> library.</p> <p>To define a column, the following attributes are required:</p> <ul> <li><code>name</code>: name of the column.</li> <li><code>dtype</code>: represents the datatype and should be an instance of <code>DataType</code>.</li> <li><code>parser</code>: a column in <code>hamana</code> could have an associated <code>parser</code> object      that could be used to parse list of values; e.g. useful when data are      extracted from different data sources and should be casted  and normalized.</li> </ul>"},{"location":"core/column.html#hamana.core.column.Column.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of the column.</p>"},{"location":"core/column.html#hamana.core.column.Column.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype: DataType\n</code></pre> <p>Data type of the column.</p>"},{"location":"core/column.html#hamana.core.column.Column.parser","title":"parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>parser: ColumnParser | None = None\n</code></pre> <p>Parser object for the column.</p>"},{"location":"core/column.html#hamana.core.column.Column.order","title":"order  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>order: int | None = None\n</code></pre> <p>Numerical order of the column.</p>"},{"location":"core/column.html#hamana.core.column.Column.inferred","title":"inferred  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inferred: bool = False\n</code></pre> <p>Flag to indicate if the column was inferred.</p>"},{"location":"core/column.html#hamana.core.column.NumberColumn","title":"hamana.core.column.NumberColumn","text":"<pre><code>NumberColumn(\n    name: str,\n    decimal_separator: str = \".\",\n    thousands_separator: str = \",\",\n    null_default_value: int | float | None = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>Column</code></p> <p>Dedicated class representing <code>DataType.NUMBER</code> columns. </p> <p>The class provides attributes that could be used to define  the properties of the number column, such as:</p> <ul> <li><code>decimal_separator</code>: the decimal separator used in the number.     By default, the decimal separator is set to <code>.</code>.</li> <li><code>thousands_separator</code>: the thousands separator used in the number.     By default, the thousands separator is set to <code>,</code>.</li> <li><code>null_default_value</code>: the default value to be used when a null value is found.     By default, the default value is set to <code>None</code>.</li> </ul> <p>The class also provides a default parser that could be used to parse  the number column using <code>pandas</code>.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    decimal_separator: str = \".\",\n    thousands_separator: str = \",\",\n    null_default_value: int | float | None = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None\n):\n    # set the attributes\n    self.decimal_separator = decimal_separator\n    self.thousands_separator = thousands_separator\n    self.null_default_value = null_default_value\n    self.parser: ColumnParser # type: ignore\n\n    logger.debug(f\"decimal separator: {self.decimal_separator}\")\n    logger.debug(f\"thousands separator: {self.thousands_separator}\")\n    logger.debug(f\"null default value: {self.null_default_value}\")\n\n    # set default parser\n    if parser is None:\n        logger.debug(\"set default parser\")\n        parser = ColumnParser(pandas = self.pandas_default_parser)\n\n    # call the parent class constructor\n    super().__init__(name, DataType.NUMBER, parser, order)\n\n    return\n</code></pre>"},{"location":"core/column.html#hamana.core.column.NumberColumn.decimal_separator","title":"decimal_separator  <code>instance-attribute</code>","text":"<pre><code>decimal_separator: str = decimal_separator\n</code></pre> <p>Decimal separator used in the number.</p>"},{"location":"core/column.html#hamana.core.column.NumberColumn.thousands_separator","title":"thousands_separator  <code>instance-attribute</code>","text":"<pre><code>thousands_separator: str = thousands_separator\n</code></pre> <p>Thousands separator used in the number.</p>"},{"location":"core/column.html#hamana.core.column.NumberColumn.null_default_value","title":"null_default_value  <code>instance-attribute</code>","text":"<pre><code>null_default_value: int | float | None = null_default_value\n</code></pre> <p>Default value to be used when a null value is found.</p>"},{"location":"core/column.html#hamana.core.column.NumberColumn.pandas_default_parser","title":"pandas_default_parser","text":"<pre><code>pandas_default_parser(\n    series: PandasSeries,\n    mode: PandasParsingModes = PandasParsingModes.RAISE,\n) -&gt; PandasSeries\n</code></pre> <p>Default <code>pandas</code> parser for the number columns. The function  converts first the column to string type and replaces the  thousands separator with an empty string and the decimal  separator with <code>.</code>. Then, the function tries to convert the  column to a numeric type using the <code>pandas.to_numeric</code>.</p> <p>If the <code>null_default_value</code> is set, the function fills the  null values with the default value.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be parsed.</p> required <code>mode</code> <code>PandasParsingModes</code> <p>mode to be used when parsing the number column. By default, the mode is set to <code>PandasParsingModes.RAISE</code>.</p> <code>PandasParsingModes.RAISE</code> <p>Returns:</p> Type Description <code>PandasSeries</code> <p><code>pandas</code> series parsed.</p> <p>Raises:</p> Type Description <code>`ColumnParserPandasNumberError`</code> <p>error parsing the number column.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def pandas_default_parser(self, series: PandasSeries, mode: PandasParsingModes = PandasParsingModes.RAISE) -&gt; PandasSeries:\n    \"\"\"\n        Default `pandas` parser for the number columns. The function \n        converts first the column to string type and replaces the \n        thousands separator with an empty string and the decimal \n        separator with `.`. Then, the function tries to convert the \n        column to a numeric type using the `pandas.to_numeric`.\n\n        If the `null_default_value` is set, the function fills the \n        null values with the default value.\n\n        Parameters:\n            series: `pandas` series to be parsed.\n            mode: mode to be used when parsing the number column.\n                By default, the mode is set to `PandasParsingModes.RAISE`.\n\n        Returns:\n            `pandas` series parsed.\n\n        Raises:\n            `ColumnParserPandasNumberError`: error parsing the number column.\n    \"\"\"\n\n    _series = pd.Series(np.nan, index = series.index)\n    try:\n        _series_number = pd.to_numeric(series.dropna().astype(\"str\").str.replace(self.thousands_separator, \"\").str.replace(self.decimal_separator, \".\"), errors = mode.value) # type: ignore (pandas issue in typing)\n        _series.loc[_series_number.index] = _series_number\n    except Exception as e:\n        logger.error(f\"error parsing number: {e}\")\n        raise ColumnParserPandasNumberError(f\"error parsing number: {e}\")\n\n    if self.null_default_value is not None:\n        logger.debug(f\"fill nulls, default value: {self.null_default_value}\")\n        _series = _series.fillna(self.null_default_value)\n    return _series.astype(\"float\")\n</code></pre>"},{"location":"core/column.html#hamana.core.column.IntegerColumn","title":"hamana.core.column.IntegerColumn","text":"<pre><code>IntegerColumn(\n    name: str,\n    decimal_separator: str = \".\",\n    thousands_separator: str = \",\",\n    null_default_value: int | None = 0,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>NumberColumn</code></p> <p>Class representing <code>DataType.INTEGER</code> columns.  It ehrits from the <code>NumberColumn</code> class and provides  a default parser that could be used to parse integer columns.</p> <p>Similar to the <code>NumberColumn</code> class, the <code>IntegerColumn</code> class provides attributes that could be used to define the properties of the integer column, such as:</p> <ul> <li><code>decimal_separator</code>: the decimal separator used in the number.     By default, the decimal separator is set to <code>.</code>.</li> <li><code>thousands_separator</code>: the thousands separator used in the number.     By default, the thousands separator is set to <code>,</code>.</li> <li><code>null_default_value</code>: the default value to be used when a null value is found.     By default, the default value is set to <code>0</code>.</li> </ul> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    decimal_separator: str = \".\",\n    thousands_separator: str = \",\",\n    null_default_value: int | None = 0,\n    parser: ColumnParser | None = None,\n    order: int | None = None\n):\n\n    # call the parent class constructor\n    super().__init__(name, decimal_separator, thousands_separator, null_default_value, parser, order)\n\n    # override types\n    self.dtype = DataType.INTEGER\n</code></pre>"},{"location":"core/column.html#hamana.core.column.IntegerColumn.pandas_default_parser","title":"pandas_default_parser","text":"<pre><code>pandas_default_parser(\n    series: PandasSeries,\n    mode: PandasParsingModes = PandasParsingModes.RAISE,\n) -&gt; PandasSeries\n</code></pre> <p>Default <code>pandas</code> parser for the integer columns. Similar  to the <code>NumberColumn</code> class, the function converts first  the column to string type and replaces the thousands separator with an empty string and the decimal separator with <code>.</code>.  Then, the function tries to convert the column to a numeric type using the <code>pandas.to_numeric</code>.</p> <p>If the <code>null_default_value</code> is set, the function fills the null values with the default value, and casts the column to  integer type. Otherwise, the function applies the <code>np.floor</code> function to the returned series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be parsed.</p> required <code>mode</code> <code>PandasParsingModes</code> <p>mode to be used when parsing the number column. By default, the mode is set to <code>PandasParsingModes.RAISE</code>.</p> <code>PandasParsingModes.RAISE</code> <p>Returns:</p> Type Description <code>PandasSeries</code> <p><code>pandas</code> series parsed.</p> <p>Raises:</p> Type Description <code>`ColumnParserPandasNumberError`</code> <p>error parsing the number column.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def pandas_default_parser(self, series: PandasSeries, mode: PandasParsingModes = PandasParsingModes.RAISE) -&gt; PandasSeries:\n    \"\"\"\n        Default `pandas` parser for the integer columns. Similar \n        to the `NumberColumn` class, the function converts first \n        the column to string type and replaces the thousands separator\n        with an empty string and the decimal separator with `.`. \n        Then, the function tries to convert the column to a numeric\n        type using the `pandas.to_numeric`.\n\n        If the `null_default_value` is set, the function fills the\n        null values with the default value, and casts the column to \n        integer type. Otherwise, the function applies the `np.floor`\n        function to the returned series.\n\n        Parameters:\n            series: `pandas` series to be parsed.\n            mode: mode to be used when parsing the number column.\n                By default, the mode is set to `PandasParsingModes.RAISE`.\n\n        Returns:\n            `pandas` series parsed.\n\n        Raises:\n            `ColumnParserPandasNumberError`: error parsing the number column.\n    \"\"\"\n\n    _series = pd.Series(np.nan, index = series.index)\n    try:\n        _series_number = pd.to_numeric(\n            arg = series.dropna().astype(\"str\").str.replace(self.thousands_separator, \"\").str.replace(self.decimal_separator, \".\"),\n            errors = mode.value # type: ignore (pandas issue in typing)\n        )\n        _series.loc[_series_number.index] = _series_number\n    except Exception as e:\n        logger.error(f\"error parsing integer: {e}\")\n        raise ColumnParserPandasNumberError(f\"error parsing integer: {e}\")\n\n    if self.null_default_value is not None:\n        logger.debug(f\"fill nulls, default value: {self.null_default_value}\")\n        return pd.Series(_series, dtype = \"float\").fillna(self.null_default_value).astype(\"int\")\n\n    return pd.Series(_series.astype(float).apply(np.floor), dtype = \"Int64\")\n</code></pre>"},{"location":"core/column.html#hamana.core.column.StringColumn","title":"hamana.core.column.StringColumn","text":"<pre><code>StringColumn(\n    name: str,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>Column</code></p> <p>Class representing <code>DataType.STRING</code> columns.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    parser: ColumnParser | None = None,\n    order: int | None = None\n):\n\n    self.parser: ColumnParser # type: ignore\n\n    # set default parser\n    if parser is None:\n        logger.debug(\"set default parser\")\n        parser = ColumnParser(pandas = self.pandas_default_parser)\n\n    # call the parent class constructor\n    super().__init__(name, DataType.STRING, parser, order)\n\n    return\n</code></pre>"},{"location":"core/column.html#hamana.core.column.StringColumn.pandas_default_parser","title":"pandas_default_parser","text":"<pre><code>pandas_default_parser(series: PandasSeries) -&gt; PandasSeries\n</code></pre> <p>Default <code>pandas</code> parser for the string columns. The function converts the column to string type and replaces the null values with <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be parsed.</p> required <p>Returns:</p> Type Description <code>PandasSeries</code> <p><code>pandas</code> series parsed</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def pandas_default_parser(self, series: PandasSeries) -&gt; PandasSeries:\n    \"\"\"\n        Default `pandas` parser for the string columns. The function\n        converts the column to string type and replaces the null values\n        with `None`.\n\n        Parameters:\n            series: `pandas` series to be parsed.\n\n        Returns:\n            `pandas` series parsed\n    \"\"\"\n    _series_nulls = series.isnull()\n    return series.astype(\"str\").where(~_series_nulls, None)\n</code></pre>"},{"location":"core/column.html#hamana.core.column.BooleanColumn","title":"hamana.core.column.BooleanColumn","text":"<pre><code>BooleanColumn(\n    name: str,\n    true_value: str | int | float = \"Y\",\n    false_value: str | int | float = \"N\",\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>Column</code></p> <p>Class representing <code>DataType.BOOLEAN</code> columns.</p> <p>The class provides attributes that could be used to define  the properties of the boolean column, such as: </p> <ul> <li><code>true_value</code>: the value to be used to represent the <code>True</code> value.     By default, the value is set to <code>Y</code>.</li> <li><code>false_value</code>: the value to be used to represent the <code>False</code> value.     By default, the value is set to <code>N</code>.</li> </ul> <p>The class also provides a default parser that could be used to parse the boolean column using <code>pandas</code>.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(self,\n    name: str,\n    true_value: str | int | float = \"Y\",\n    false_value: str | int | float = \"N\",\n    parser: ColumnParser | None = None,\n    order: int | None = None\n) -&gt; None:\n\n    # set attributes\n    self.true_value = true_value\n    self.false_value = false_value\n    self.parser: ColumnParser # type: ignore\n\n    logger.debug(f\"true value: {self.true_value}\")\n    logger.debug(f\"false value: {self.false_value}\")\n\n    # set default parser\n    if parser is None:\n        logger.debug(\"set default parser\")\n        parser = ColumnParser(pandas = self.pandas_default_parser)\n\n    # call the parent class constructor\n    super().__init__(name, DataType.BOOLEAN, parser, order)\n\n    return\n</code></pre>"},{"location":"core/column.html#hamana.core.column.BooleanColumn.true_value","title":"true_value  <code>instance-attribute</code>","text":"<pre><code>true_value: str | int | float = true_value\n</code></pre> <p>Value to be used to represent the <code>True</code> value.</p>"},{"location":"core/column.html#hamana.core.column.BooleanColumn.false_value","title":"false_value  <code>instance-attribute</code>","text":"<pre><code>false_value: str | int | float = false_value\n</code></pre> <p>Value to be used to represent the <code>False</code> value.</p>"},{"location":"core/column.html#hamana.core.column.BooleanColumn.pandas_default_parser","title":"pandas_default_parser","text":"<pre><code>pandas_default_parser(series: PandasSeries) -&gt; PandasSeries\n</code></pre> <p>Default <code>pandas</code> parser for the boolean columns. The function maps the values to <code>True</code> and <code>False</code>  based on the <code>true_value</code> and <code>false_value</code> attributes.</p> <p>Observe that all other values are set to <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be parsed.</p> required <p>Returns:</p> Type Description <code>PandasSeries</code> <p><code>pandas</code> series parsed.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def pandas_default_parser(self, series: PandasSeries) -&gt; PandasSeries:\n    \"\"\"\n        Default `pandas` parser for the boolean columns.\n        The function maps the values to `True` and `False` \n        based on the `true_value` and `false_value` attributes.\n\n        Observe that all other values are set to `None`.\n\n        Parameters:\n            series: `pandas` series to be parsed.\n\n        Returns:\n            `pandas` series parsed.\n    \"\"\"\n    return series.map({self.true_value: True, self.false_value: False})\n</code></pre>"},{"location":"core/column.html#hamana.core.column.DatetimeColumn","title":"hamana.core.column.DatetimeColumn","text":"<pre><code>DatetimeColumn(\n    name: str,\n    format: str = \"%Y-%m-%d %H:%M:%S\",\n    null_default_value: (\n        datetime | pd.Timestamp | None\n    ) = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>Column</code></p> <p>Class representing <code>DataType.DATETIME</code> columns.</p> <p>The class provides attributes that could be used to define  the properties of the datetime column, such as:</p> <ul> <li><code>format</code>: the format to be used to parse the datetime.     By default, the format is set to <code>%Y-%m-%d %H:%M:%S</code>.</li> <li><code>null_default_value</code>: the default value to be used when a null value is found.     By default, the default value is set to <code>None</code>.</li> </ul> <p>The class also provides a default parser that could be used to parse the datetime column using <code>pandas</code>.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(self,\n    name: str,\n    format: str = \"%Y-%m-%d %H:%M:%S\",\n    null_default_value: datetime | pd.Timestamp | None = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None\n) -&gt; None:\n\n    # set attributes\n    self.format = format\n    self.null_default_value = null_default_value\n    self.parser: ColumnParser # type: ignore\n\n    logger.debug(f\"format: {self.format}\")\n    logger.debug(f\"null default value: {self.null_default_value}\")\n\n    # set default parser\n    if parser is None:\n        logger.debug(\"set default parser\")\n        parser = ColumnParser(pandas = self.pandas_default_parser)\n\n    # call the parent class constructor\n    super().__init__(name, DataType.DATETIME, parser, order)\n\n    return\n</code></pre>"},{"location":"core/column.html#hamana.core.column.DatetimeColumn.format","title":"format  <code>instance-attribute</code>","text":"<pre><code>format: str = format\n</code></pre> <p>Format to be used to parse the datetime.</p>"},{"location":"core/column.html#hamana.core.column.DatetimeColumn.null_default_value","title":"null_default_value  <code>instance-attribute</code>","text":"<pre><code>null_default_value: datetime | pd.Timestamp | None = (\n    null_default_value\n)\n</code></pre> <p>Default value to be used when a null value is found.</p>"},{"location":"core/column.html#hamana.core.column.DatetimeColumn.pandas_default_parser","title":"pandas_default_parser","text":"<pre><code>pandas_default_parser(\n    series: PandasSeries,\n    mode: PandasParsingModes = PandasParsingModes.RAISE,\n) -&gt; PandasSeries\n</code></pre> <p>Default <code>pandas</code> parser for the datetime columns. The function tries to convert the column to a datetime type using the <code>pandas.to_datetime</code>.</p> <p>Observe that <code>pandas.to_datetime</code> could raise an <code>OutOfBoundsDatetime</code> error when the datetime is out of bounds. In this case, the function switches to a 'slow' mode where it first converts the column to string type and divides  it into two parts:</p> <ul> <li>the part that could be casted to datetime using the <code>pandas.to_datetime</code>.</li> <li>the part that could not be casted, and should be parsed using the <code>dateutil.parser</code>.</li> </ul> <p>This approach is slower than the default one, but can handle out of bounds datetimes.</p> <p>Finally, the function fills the null values with the default value, if set.</p> <p>If the <code>null_default_value</code> is set, the function fills the null values with the default value.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>PandasSeries</code> <p><code>pandas</code> series to be parsed.</p> required <code>mode</code> <code>PandasParsingModes</code> <p>mode to be used when parsing the datetime column. By default, the mode is set to <code>PandasParsingModes.RAISE</code>.</p> <code>PandasParsingModes.RAISE</code> <p>Returns:</p> Type Description <code>PandasSeries</code> <p><code>pandas</code> series parsed.</p> <p>Raises:</p> Type Description <code>`ColumnParserPandasDatetimeError`</code> <p>error parsing the datetime column.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def pandas_default_parser(self, series: PandasSeries, mode: PandasParsingModes = PandasParsingModes.RAISE) -&gt; PandasSeries:\n    \"\"\"\n        Default `pandas` parser for the datetime columns. The function\n        tries to convert the column to a datetime type using the `pandas.to_datetime`.\n\n        Observe that `pandas.to_datetime` could raise an `OutOfBoundsDatetime` error\n        when the datetime is out of bounds. In this case, the function switches to\n        a 'slow' mode where it first converts the column to string type and divides \n        it into two parts:\n\n        - the part that could be casted to datetime using the `pandas.to_datetime`.\n        - the part that could not be casted, and should be parsed using the `dateutil.parser`.\n\n        This approach is slower than the default one, but can handle out of bounds datetimes.\n\n        Finally, the function fills the null values with the default value, if set.\n\n        If the `null_default_value` is set, the function fills the null values\n        with the default value.\n\n        Parameters:\n            series: `pandas` series to be parsed.\n            mode: mode to be used when parsing the datetime column.\n                By default, the mode is set to `PandasParsingModes.RAISE`.\n\n        Returns:\n            `pandas` series parsed.\n\n        Raises:\n            `ColumnParserPandasDatetimeError`: error parsing the datetime column.\n    \"\"\"\n\n    _series: PandasSeries\n    _series_nulls = series.isnull()\n\n    try:\n        _series = pd.Series(pd.NaT, index = series.index)\n        _series_dt = pd.to_datetime(series.dropna().astype(\"str\"), errors = mode.value, format = self.format) # type: ignore (pandas issue in typing)\n        _series.loc[_series_dt.index] = _series_dt\n    except OutOfBoundsDatetime as e:\n        logger.warning(\"[WARNING] switched to 'slow' mode due to out of bounds datetimes\")\n        logger.debug(f\"[WARNING] parsing datetime: {e}\")\n        _series = pd.to_datetime(series.astype(\"str\"), errors = \"coerce\", format = self.format)\n        _series_not_casted = _series.isnull() &amp; ~_series_nulls\n        _series_to_cast = series.where(_series_not_casted, None)\n        _series = _series.where(~_series_not_casted, _series_to_cast.dropna().apply(parser.parse))\n    except Exception as e:\n        logger.error(f\"error parsing datetime: {e}\")\n        raise ColumnParserPandasDatetimeError(f\"error parsing datetime: {e}\")\n\n    logger.debug(\"update null values\")\n    if _series_nulls.sum() &gt; 0 and self.null_default_value is not None:\n        logger.info(\"fill nulls\")\n\n        if (\n                self.null_default_value &gt;= pd.Timestamp.min\n            and self.null_default_value &lt;= pd.Timestamp.max\n            and \"datetime64\" in _series.dtype.name\n        ):\n            _series = _series.fillna(self.null_default_value)\n        else:\n            _series = _series.mask(_series_nulls, self.null_default_value)\n\n    return _series\n</code></pre>"},{"location":"core/column.html#hamana.core.column.DateColumn","title":"hamana.core.column.DateColumn","text":"<pre><code>DateColumn(\n    name: str,\n    format: str = \"%Y-%m-%d\",\n    null_default_value: (\n        datetime | pd.Timestamp | None\n    ) = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None,\n)\n</code></pre> <p>               Bases: <code>DatetimeColumn</code></p> <p>Class representing <code>DataType.DATE</code> columns.</p> <p>The class inherits from the <code>DatetimeColumn</code> class and can  be used to store date values. Different from the <code>DatetimeColumn</code> class, the <code>DateColumn</code> class does not store the time part of the datetime.</p> Note <p>During the initialization, the <code>format</code> is analysed to ensure that no  time part is present. If the time part is found, an error is raised.</p> <p>Similar to the <code>DatetimeColumn</code> class, the <code>DateColumn</code> class provides attributes  that could be used to define the properties of the date column, such as:</p> <ul> <li><code>format</code>: the format to be used to parse the date.     By default, the format is set to <code>%Y-%m-%d</code>.</li> <li><code>null_default_value</code>: the default value to be used when a null value is found.     By default, the default value is set to <code>None</code>.</li> </ul> <p>Raises:</p> Type Description <code>`ColumnDateFormatterError`</code> <p>error raised when the date format contains a time part.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>def __init__(self,\n    name: str,\n    format: str = \"%Y-%m-%d\",\n    null_default_value: datetime | pd.Timestamp | None = None,\n    parser: ColumnParser | None = None,\n    order: int | None = None\n) -&gt; None:\n\n    # check format\n    self.check_format(format)\n\n    # call the parent class constructor\n    super().__init__(name, format, null_default_value, parser, order)\n\n    # override types\n    self.dtype = DataType.DATE\n\n    return\n</code></pre>"},{"location":"core/column.html#hamana.core.column.DateColumn.check_format","title":"check_format  <code>staticmethod</code>","text":"<pre><code>check_format(format: str) -&gt; None\n</code></pre> <p>Function to check if the date format contains a time part.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>date format to be checked.</p> required <p>Raises:</p> Type Description <code>`ColumnDateFormatterError`</code> <p>error raised when the date format contains a time part.</p> Source code in <code>src/hamana/core/column.py</code> <pre><code>@staticmethod\ndef check_format(format: str) -&gt; None:\n    \"\"\"\n        Function to check if the date format contains a time part.\n\n        Parameters:\n            format: date format to be checked.\n\n        Raises:\n            `ColumnDateFormatterError`: error raised when the date format contains a time part.\n    \"\"\"\n    not_admissible_formats = [\"%H\", \"%I\", \"%p\", \"%M\", \"%S\", \"%f\", \"%z\", \"%c\", \"%X\"]\n    if any([f in format for f in not_admissible_formats]):\n        raise ColumnDateFormatterError(f\"date format {format} should not contain time part\")\n</code></pre>"},{"location":"core/query.html","title":"Query","text":"<p>The <code>hamana</code> library provides many classes to extract data from different sources, the <code>Query</code> class was introduced to provide a common interface to interact with these classes (connectors) or with the extracted data.</p> <p>For example, when dealing with Database connectors, it can be used to execute SQL queries, while for File connectors, it is used to manage the extracted data. In addition, <code>Query</code> objects are natively connected with <code>hamana</code> internal database and can be used to perform operations on the extracted data.</p> <p>Due to its frequent use, the <code>Query</code> class is available in the <code>hamana</code> module, so it can be imported directly from there. See all details in the API section.</p>"},{"location":"core/query.html#examples","title":"Examples","text":"<p>This example shows how to use the <code>Query</code> class to execute a SQL query on an in-memory database.</p> <pre><code>import hamana as hm\n\n# connect to in-memory database\nhm.connect()\n\n# define and execute a query\nquery = hm.Query(\"SELECT * FROM customers\")\nresult = query.execute().reults\n\nprint(result.info())\n\n# close connection\nhm.disconnect()\n</code></pre> <p>This other example shows how to use the <code>Query</code> class to manage the extracted data from a CSV file.</p> <pre><code>import hamana as hm\n\n# connect to CSV file\ncustomers_csv = hm.connector.file.CSV(\"customers.csv\")\nquery = customers_csv.execute()\n\n# check results\nprint(query.result.info())\n</code></pre>"},{"location":"core/query.html#api","title":"API","text":""},{"location":"core/query.html#hamana.connector.db.query.Query","title":"hamana.connector.db.query.Query","text":"<pre><code>Query(\n    query: str | Path,\n    columns: list[TColumn] | None = None,\n    params: (\n        list[QueryParam] | dict[str, ParamValue] | None\n    ) = None,\n)\n</code></pre> <p>               Bases: <code>Generic[TColumn]</code></p> <p>Class to represent a query object.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def __init__(\n    self,\n    query: str | Path,\n    columns: list[TColumn] | None = None,\n    params: list[QueryParam] | dict[str, ParamValue] | None = None\n) -&gt; None:\n\n    # setup query\n    if isinstance(query, Path):\n        logger.info(f\"loading query from file: {query}\")\n\n        if not query.exists():\n            raise QueryInitializationError(f\"file {query} not found\")\n\n        self.query = query.read_text()\n    elif isinstance(query, str):\n        if Path(query).exists():\n            logger.info(f\"loading query from file: {query}\")\n            with open(query, \"r\") as f:\n                self.query = f.read()\n        else:\n            self.query = query\n\n    self.columns = columns\n    self.params = params\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.query","title":"query  <code>instance-attribute</code>","text":"<pre><code>query: str\n</code></pre> <p>Query to be executed in the database. It is possible to provide directly the  SQL query as a string or to load it from a file by providing the file path.</p>"},{"location":"core/query.html#hamana.connector.db.query.Query.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: list[QueryParam] | dict[str, ParamValue] | None = (\n    None\n)\n</code></pre> <p>List of parameters used in the query.  The parameters are replaced by their values when the query is executed.</p>"},{"location":"core/query.html#hamana.connector.db.query.Query.columns","title":"columns  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>columns: list[TColumn] | None = None\n</code></pre> <p>Definition of the columns returned by the query.  The columns are used to map the query result to the application data. If not provided, then the columns are inferred from the result.</p>"},{"location":"core/query.html#hamana.connector.db.query.Query.flag_executed","title":"flag_executed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>flag_executed: bool = False\n</code></pre> <p>Flag to indicate if the query has been executed.</p>"},{"location":"core/query.html#hamana.connector.db.query.Query.result","title":"result  <code>property</code> <code>writable</code>","text":"<pre><code>result: pd.DataFrame\n</code></pre> <p>Result of the query execution.  The result is a <code>pandas.DataFrame</code> with columns equals the ones defined in the <code>columns</code> attribute,  or inferred from the extraction.</p> <p>Raises:</p> Type Description <code>QueryResultNotAvailable</code> <p>if no result is available; e.g., the query has not been executed.</p>"},{"location":"core/query.html#hamana.connector.db.query.Query.get_params","title":"get_params","text":"<pre><code>get_params() -&gt; dict[str, ParamValue] | None\n</code></pre> <p>Returns the query parameters as a dictionary. Returns <code>None</code> if there are no parameters.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def get_params(self) -&gt; dict[str, ParamValue] | None:\n    \"\"\"\n        Returns the query parameters as a dictionary.\n        Returns `None` if there are no parameters.\n    \"\"\"\n    if isinstance(self.params, list):\n        _params = {param.name : param.value for param in self.params}\n    else:\n        _params = self.params\n    return _params\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.to_sqlite","title":"to_sqlite","text":"<pre><code>to_sqlite(\n    table_name: str,\n    mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE,\n) -&gt; None\n</code></pre> <p>This function is used to insert the query result into a  table hosted on the <code>hamana</code> internal database (<code>HamanaConnector</code>).</p> <p>The <code>hamana</code> db is a SQLite database, for this reason  <code>bool</code>, <code>datetime</code> and <code>timestamp</code> data types are not supported. If some of the columns are defined with these data types,  then the method performs an automatic conversion to a SQLite data type.</p> <p>In particular, the conversions are:</p> <ul> <li><code>bool</code> columns are mapped to <code>INTEGER</code> data type, with the values  <code>True</code> and <code>False</code> converted to <code>1</code> and <code>0</code>.</li> <li><code>date</code> and <code>datetime</code> columns are mapped to <code>INTEGER</code> datatype, with the values      converted to an int number using the following format: <code>YYYYMMDDHHmmss</code>     for <code>dateitme</code>, <code>YYYYMMDD</code> for <code>date</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of the table to create into the database. By assumption, the table's name is converted to uppercase.</p> required <code>mode</code> <code>SQLiteDataImportMode</code> <p>mode of importing the data into the database.</p> <code>SQLiteDataImportMode.REPLACE</code> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def to_sqlite(self, table_name: str, mode: SQLiteDataImportMode = SQLiteDataImportMode.REPLACE) -&gt; None:\n    \"\"\"\n        This function is used to insert the query result into a \n        table hosted on the `hamana` internal database (`HamanaConnector`).\n\n        The `hamana` db is a SQLite database, for this reason \n        `bool`, `datetime` and `timestamp` data types are **not** supported.\n        If some of the columns are defined with these data types, \n        then the method performs an automatic conversion to a SQLite data type.\n\n        In particular, the conversions are:\n\n        - `bool` columns are mapped to `INTEGER` data type, with the values \n        `True` and `False` converted to `1` and `0`.\n        - `date` and `datetime` columns are mapped to `INTEGER` datatype, with the values \n            converted to an int number using the following format: `YYYYMMDDHHmmss`\n            for `dateitme`, `YYYYMMDD` for `date`.\n\n        Parameters:\n            table_name: name of the table to create into the database.\n                By assumption, the table's name is converted to uppercase.\n            mode: mode of importing the data into the database.\n    \"\"\"\n    logger.debug(\"start\")\n    df_insert = self.result.copy()\n\n    # set dtype\n    columns_dtypes: dict | None = None\n    if self.columns is not None:\n        columns_dtypes = {}\n        for column in self.columns:\n            columns_dtypes[column.name] = DataType.to_sqlite(column.dtype)\n\n            # convert columns\n            match column.dtype:\n                case DataType.BOOLEAN:\n                    df_insert[column.name] = df_insert[column.name].astype(int)\n                case DataType.DATE:\n                    df_insert[column.name] = df_insert[column.name].dt.strftime(\"%Y%m%d\").astype(int)\n                case DataType.DATETIME:\n                    df_insert[column.name] = df_insert[column.name].dt.strftime(\"%Y%m%d%H%M%S\").astype(int)\n\n    # import internal database\n    from .hamana import HamanaConnector\n\n    # get instance\n    db = HamanaConnector.get_instance()\n\n    # insert data\n    table_name_upper = table_name.upper()\n    try:\n        with db:\n            logger.debug(f\"inserting data into table {table_name_upper}\")\n            logger.debug(f\"mode: {mode.value}\")\n            df_insert.to_sql(\n                name = table_name_upper,\n                con = db.connection,\n                if_exists = mode.value,\n                dtype = columns_dtypes,\n                index = False\n            )\n            logger.info(f\"data inserted into table {table_name_upper}\")\n    except Exception as e:\n        logger.error(f\"error inserting data into table {table_name_upper}\")\n        logger.exception(e)\n        raise e\n\n    logger.debug(\"end\")\n    return\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.get_insert_query","title":"get_insert_query","text":"<pre><code>get_insert_query(table_name: str) -&gt; str\n</code></pre> <p>This function returns a query to insert the query result into a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of the table to insert the data. By assumption, the table's name is converted to uppercase.</p> required <p>Returns:</p> Type Description <code>str</code> <p>query to insert the data into the table.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def get_insert_query(self, table_name: str) -&gt; str:\n    \"\"\"\n        This function returns a query to insert the query result into a table.\n\n        Parameters:\n            table_name: name of the table to insert the data.\n                By assumption, the table's name is converted to uppercase.\n\n        Returns:\n            query to insert the data into the table.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # check columns availablity\n    if self.columns is None:\n        logger.error(\"no columns available\")\n        raise QueryColumnsNotAvailable(\"no columns available\")\n\n    # get columns\n    columns = \", \".join([column.name for column in self.columns])\n    logger.debug(\"columns string created\")\n\n    # get values\n    values = \", \".join([\"?\" for _ in self.columns])\n    logger.debug(\"values string created\")\n\n    # build query\n    table_name_upper = table_name.upper()\n    query = f\"INSERT INTO {table_name_upper} ({columns}) VALUES ({values})\"\n    logger.info(f\"query to insert data into table {table_name_upper} created\")\n    logger.info(f\"query: {query}\")\n\n    logger.debug(\"end\")\n    return query\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.get_create_query","title":"get_create_query","text":"<pre><code>get_create_query(table_name: str) -&gt; str\n</code></pre> <p>This function returns a query to create a table based on the query result.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of the table to be created. By assumption, the table's name is converted to uppercase.</p> required <p>Returns:</p> Type Description <code>str</code> <p>query to create the table.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def get_create_query(self, table_name: str) -&gt; str:\n    \"\"\"\n        This function returns a query to create a table based on the query result.\n\n        Parameters:\n            table_name: name of the table to be created.\n                By assumption, the table's name is converted to uppercase.\n\n        Returns:\n            query to create the table.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # check columns availablity\n    if self.columns is None:\n        logger.error(\"no columns available\")\n        raise QueryColumnsNotAvailable(\"no columns available\")\n\n    # build query\n    table_name_upper = table_name.upper()\n    query = \"CREATE TABLE \" + table_name_upper + \" (\\n\" + \\\n            \"\".rjust(4) + \", \".rjust(4).join([f\"{column.name} {DataType.to_sqlite(column.dtype)}\\n\" for column in self.columns]) + \\\n            \")\"\n    logger.info(f\"query to create table {table_name_upper} created\")\n    logger.info(f\"query: {query}\")\n\n    logger.debug(\"end\")\n    return query\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.get_column_names","title":"get_column_names","text":"<pre><code>get_column_names() -&gt; list[str]\n</code></pre> <p>This function returns the column names of the query.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list of column names.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def get_column_names(self) -&gt; list[str]:\n    \"\"\"\n        This function returns the column names of the query.\n\n        Returns:\n            list of column names.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # check columns availablity\n    if self.columns is None:\n        logger.error(\"no columns available\")\n        raise QueryColumnsNotAvailable(\"no columns available\")\n    columns = [column.name for column in self.columns]\n\n    logger.debug(\"end\")\n    return columns\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.Query.adjust_df","title":"adjust_df","text":"<pre><code>adjust_df(df: pd.DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>This function is used to adjust a <code>pandas.DataFrame</code> (usually  the result of a query) based on the columns provided.</p> <p>The function re-orders the columns of the <code>DataFrame</code>  and checks the data types; if they do not match, then  the function will try to convert the requested one.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>DataFrame to adjust</p> required <p>Raises:</p> Type Description <code>QueryColumnsNotAvailable</code> <p>if the columns do not match between the query and the result.</p> <code>ColumnDataTypeConversionError</code> <p>if there is an error during the data type conversion.</p> Source code in <code>src/hamana/connector/db/query.py</code> <pre><code>def adjust_df(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n        This function is used to adjust a `pandas.DataFrame` (usually \n        the result of a query) based on the columns provided.\n\n        The function re-orders the columns of the `DataFrame` \n        and checks the data types; if they do not match, then \n        the function will try to convert the requested one.\n\n        Parameters:\n            df: DataFrame to adjust\n\n        Raises:\n            QueryColumnsNotAvailable: if the columns do not match between the query and the result.\n            ColumnDataTypeConversionError: if there is an error during the data type conversion.\n    \"\"\"\n    logger.debug(\"start\")\n\n    # check columns availablity\n    if self.columns is None:\n        logger.error(\"no columns available\")\n        raise QueryColumnsNotAvailable(\"no columns available\")\n    columns = self.columns\n\n    # get columns\n    columns_query = []\n    columns_df = df.columns.to_list()\n\n    logger.info(\"get query columns ordered\")\n    for col in sorted(columns, key = lambda col: col.order if col.order is not None else 0):\n        columns_query.append(col.name)\n\n    # check columns_query is a subset of columns_df\n    if not set(columns_query).issubset(columns_df):\n        logger.error(\"columns do not match between query and resuls\")\n        raise QueryColumnsNotAvailable(f\"columns do not match {set(columns_query).difference(columns_df)}\")\n\n    # re-order\n    if columns_query != columns_df:\n        logger.info(\"re-ordering columns\")\n        logger.info(f\"order &gt; {columns_query}\")\n        df = df.copy()[columns_query]\n    else:\n        logger.info(\"columns already in the correct order\")\n\n    # check data types\n    logger.info(\"check data types\")\n    dtypes_df = df.dtypes\n    for column in columns:\n\n        dtype_query = column.dtype\n        dtype_df = DataType.from_pandas(dtypes_df[column.name].name)\n        logger.debug(f\"column: {column.name}\")\n        logger.debug(f\"datatype (query): {dtype_query}\")\n        logger.debug(f\"datatype (df): {dtype_df}\")\n\n        if dtype_query != dtype_df:\n            try:\n                logger.info(f\"different datatype for '{column.name}' column -&gt; (query) {dtype_query} != (df) {dtype_df}\")\n\n                if column.parser is None:\n                    logger.warning(f\"no parser available for {column.name} (order: {column.order})\")\n                    logger.warning(\"skip column\")\n                    continue\n\n                df[column.name] = column.parser.pandas(df[column.name])\n            except Exception as e:\n                logger.error(\"ERROR: on datatype change\")\n                logger.error(e)\n                raise ColumnDataTypeConversionError(f\"ERROR: on datatype change for {column.name} (order: {column.order})\")\n\n    logger.debug(\"end\")\n    return df\n</code></pre>"},{"location":"core/query.html#hamana.connector.db.query.QueryParam","title":"hamana.connector.db.query.QueryParam  <code>dataclass</code>","text":"<pre><code>QueryParam(name: str, value: ParamValue)\n</code></pre> <p>Class to represent a parameter used in a query. A parameter is represented by a name and its value.</p> <p>Usually, parameters are used to define general query conditions  and are replaced by the actual values when the query is executed.</p>"},{"location":"core/query.html#hamana.connector.db.query.QueryParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of the parameter.</p>"},{"location":"core/query.html#hamana.connector.db.query.QueryParam.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: ParamValue\n</code></pre> <p>Value of the parameter.</p>"},{"location":"core/query.html#hamana.connector.db.query.TColumn","title":"hamana.connector.db.query.TColumn  <code>module-attribute</code>","text":"<pre><code>TColumn = TypeVar('TColumn', bound=Column, covariant=True)\n</code></pre>"}]}